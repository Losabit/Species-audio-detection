{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install soundfile\n",
    "!pip install librosa\n",
    "!pip install audiomentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os, random\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import shutil\n",
    "\n",
    "from audiomentations import Compose, AddGaussianNoise, AddGaussianSNR, FrequencyMask\n",
    "from datetime import datetime\n",
    "from matplotlib import image\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.python.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from efficientnet.tfkeras import EfficientNetB1 as EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PROJECT_PATH = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "ORIGINAL_DATASET_DIRECTORY = os.path.join(PROJECT_PATH, 'dataset', 'rfcx-species-audio-detection')\n",
    "DATASET_DIRECTORY = os.path.join(PROJECT_PATH, 'dataset', 'spectrogram-species-audio-detection')\n",
    "DATASET_TRAIN_DIRECTORY = os.path.join(DATASET_DIRECTORY, 'train')\n",
    "DATASET_VAL_DIRECTORY = os.path.join(DATASET_DIRECTORY, 'val')\n",
    "DATASET_TEST_DIRECTORY = os.path.join(DATASET_DIRECTORY, 'test')\n",
    "WEIGHT_FILE_NAME = \"EfficientNet_Weights/EfficientNetBN_tl_best_weights.h5\"\n",
    "IMAGE_HEIGHT = 500\n",
    "IMAGE_WIDTH = 500\n",
    "\n",
    "# Créer une 25eme classe qui ne correspond à aucun oiseau\n",
    "USE_EMPTY_CLASS = True\n",
    "len_classes = 25 if USE_EMPTY_CLASS else 24\n",
    "epch = 600\n",
    "KERNEL_REGULARIZERS = 0.0005\n",
    "ref_lr = 0.03\n",
    "ref_batch_size = 16\n",
    "dropout = 0.2\n",
    "batch_size = 2\n",
    "momentumTest = 0.95\n",
    "destination_classes = [str(i) for i in range(len_classes)]\n",
    "### PARAMS spectrogramm_conversion ###\n",
    "# Lié à IMAGE_WIDTH et IMAGE_HEIGHT\n",
    "PERCENT_PRINT = 10\n",
    "# duration_cut -> Découpage des extraits en morceaux de x secondes / 0 = pas de découpage\n",
    "DURATION_CUT = 2\n",
    "RANDOM_CUT = True\n",
    "# Un ratio de 5 permet de sauvegarder 1 enregistrement de la 25eme classe sur 5\n",
    "# Evite d'avoir une 25eme classe trop chargée en données (sachant que 1 enregistrement contient au minimum 2 extraits)\n",
    "RATIO_EMPTY_CLASS = 40\n",
    "PRED_EMPTY_IGNORE_EXTRACT = 0.6\n",
    "# minimum duration of record\n",
    "MINIMAL_DURATION = 0.25\n",
    "MINIMAL_ANIMAL_PRESENCE = 0.25\n",
    "FREQ_MODIFIER = 0\n",
    "validation_split = 0.3\n",
    "USE_DATA_AUGMENTATION = False\n",
    "RATIO_DATA_AUG = 2\n",
    "\n",
    "\n",
    "def compute_class_images_count(base_folder: str, class_name: str):\n",
    "    return sum((1 for _ in os.listdir(f'{base_folder}/{class_name}')))\n",
    "\n",
    "\n",
    "def compute_all_classes_images_count(base_folder: str):\n",
    "    return sum((compute_class_images_count(base_folder, c) for c in destination_classes))\n",
    "\n",
    "\n",
    "def compute_train_images_count():\n",
    "    return compute_all_classes_images_count(DATASET_TRAIN_DIRECTORY)\n",
    "\n",
    "\n",
    "def compute_val_images_count():\n",
    "    return compute_all_classes_images_count(DATASET_VAL_DIRECTORY)\n",
    "\n",
    "\n",
    "def compute_total_images_count():\n",
    "    return compute_val_images_count() + compute_train_images_count()\n",
    "\n",
    "\n",
    "def compute_class_weight():\n",
    "    class_weight = {}\n",
    "    for c in destination_classes:\n",
    "        class_weight[int(c)] = compute_class_images_count(DATASET_TRAIN_DIRECTORY, c)\n",
    "        class_weight[int(c)] += compute_class_images_count(DATASET_VAL_DIRECTORY, c)\n",
    "\n",
    "    # Recuperation de la classe comportortant le moins de data\n",
    "    key_min = min(class_weight.keys(), key=(lambda k: class_weight[k]))\n",
    "    to_divide = class_weight[key_min]\n",
    "\n",
    "    for c in destination_classes:\n",
    "        class_weight[int(c)] /= to_divide\n",
    "\n",
    "    return class_weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_spectrogramm(d, s, picture_path):\n",
    "    xx, frequency, bins, im = plt.specgram(d, Fs=s)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(picture_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "    image = Image.open(picture_path)\n",
    "    image.convert('RGB').resize((IMAGE_WIDTH, IMAGE_HEIGHT)).save(picture_path)\n",
    "\n",
    "\n",
    "def save_mel_spectrogramm(d, s, picture_path):\n",
    "    spec = np.abs(librosa.stft(np.array(d), hop_length=512))\n",
    "    spec = librosa.amplitude_to_db(spec, ref=np.max)\n",
    "    librosa.display.specshow(spec, sr=s, cmap='magma')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(picture_path, bbox_inches='tight', pad_inches=0)\n",
    "    image = Image.open(picture_path)\n",
    "    image.convert('RGB').resize((IMAGE_WIDTH, IMAGE_HEIGHT)).save(picture_path)\n",
    "\n",
    "\n",
    "def save_random_brig(d, s, picture_patch):\n",
    "    spec = np.abs(librosa.stft(np.array(d), hop_length=512))\n",
    "    spec = librosa.amplitude_to_db(spec, ref=np.max)\n",
    "    librosa.display.specshow(spec, sr=s, cmap='magma')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(picture_patch, bbox_inches='tight', pad_inches=0)\n",
    "    img = Image.open(picture_patch)\n",
    "    imgArray = np.asarray(img)\n",
    "    img2 = tf.image.random_brightness(imgArray,0.2)\n",
    "    finalImag = tf.keras.preprocessing.image.array_to_img(img2)\n",
    "    finalImag.save(picture_patch)\n",
    "\n",
    "def load_data(path):\n",
    "    labels = np.zeros(0, dtype=np.float32)\n",
    "    data = np.zeros((0, IMAGE_HEIGHT, IMAGE_WIDTH, 4), dtype=np.float32)\n",
    "    for _, directories, _ in os.walk(path):\n",
    "        for directory in directories:\n",
    "            directory_path = os.path.join(path, directory)\n",
    "            for file in os.listdir(directory_path):\n",
    "                labels = np.append(labels, int(directory))\n",
    "                spectro_image = image.imread(os.path.join(directory_path, file))\n",
    "                spectro_image = np.expand_dims(spectro_image, axis=0)\n",
    "                data = np.concatenate((data, spectro_image), axis=0)\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def split_array(data_to_split, percent):\n",
    "    if percent > 1:\n",
    "        raise Exception(\"percent parameter need to be between 0 and 1\")\n",
    "\n",
    "    percent_indice = int(len(data_to_split) * percent)\n",
    "    return np.array([data_to_split[i] for i in range(percent_indice)]), \\\n",
    "           np.array([data_to_split[i] for i in range(percent_indice, len(data_to_split))])\n",
    "\n",
    "\n",
    "def build_x_y(x, y):\n",
    "    return x, tf.keras.utils.to_categorical(y, len_classes)\n",
    "\n",
    "\n",
    "def count_csv_lines(path):\n",
    "    with open(path, mode='r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        count = 0\n",
    "        for _ in reader:\n",
    "            count += 1\n",
    "        return count\n",
    "\n",
    "\n",
    "def plot_all_logs(logs):\n",
    "    print(logs)\n",
    "    metrics = ['loss', 'val_loss', 'categorical_accuracy', 'val_categorical_accuracy']\n",
    "    for metric in metrics:\n",
    "        for log in logs:\n",
    "            y_coords = log['value'].history[metric]\n",
    "            x_coords = list(range(len(y_coords)))\n",
    "            plt.plot(x_coords, y_coords)\n",
    "            plt.title(log['title'] + \" - \" + datetime.now().strftime(\"%Hh:%Mm:%Ss\") + \" - \" + metric)\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "augmentations = [\n",
    "    Compose([\n",
    "        AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "        AddGaussianSNR()\n",
    "    ]),\n",
    "    Compose([\n",
    "        FrequencyMask()\n",
    "    ])  # ,\n",
    "    # TODO : AddBackgroundNoise\n",
    "]\n",
    "\n",
    "initial_freq = 48000\n",
    "metadata_inpath = os.path.join(ORIGINAL_DATASET_DIRECTORY, 'train_tp.csv')\n",
    "audio_inpath = os.path.join(ORIGINAL_DATASET_DIRECTORY, 'train')\n",
    "number_extract_created = 0\n",
    "\n",
    "\n",
    "def determine_class_directory(t_min, t_max, current_duration, duration, species_id, is_train):\n",
    "    class_directory = \"\"\n",
    "    dataset_directory = DATASET_TRAIN_DIRECTORY if is_train else DATASET_VAL_DIRECTORY\n",
    "\n",
    "    if (t_min <= current_duration <= t_max and t_max - current_duration >= MINIMAL_ANIMAL_PRESENCE) or \\\n",
    "            (t_min <= current_duration + duration <= t_max\n",
    "             and t_max - (current_duration + duration) >= MINIMAL_ANIMAL_PRESENCE) \\\n",
    "            or (current_duration <= t_min and current_duration + duration >= t_max):\n",
    "\n",
    "        class_directory = os.path.join(dataset_directory, str(species_id))\n",
    "\n",
    "    elif USE_EMPTY_CLASS and (current_duration + duration <= t_min or current_duration >= t_max):\n",
    "        class_directory = os.path.join(dataset_directory, str(len_classes - 1))\n",
    "\n",
    "    return class_directory\n",
    "\n",
    "\n",
    "def process_data_and_save_spectrogramm(row_data, is_train):\n",
    "    global number_extract_created\n",
    "    current_duration = 0\n",
    "    it = 0\n",
    "    to_data_aug = 0\n",
    "    t_min = row_data[\"t_min\"]\n",
    "    t_max = row_data[\"t_max\"]\n",
    "    recording_id = row_data[\"recording_id\"]\n",
    "    row_species = row_data[\"species_id\"]\n",
    "\n",
    "    data, sample = sf.read(os.path.join(audio_inpath, recording_id + \".flac\"))\n",
    "    end_audio = (len(data) - 1) / sample\n",
    "\n",
    "    # print(F\"processing {recording_id}, species : {row_species} [{t_min},{t_max}] duration({end_audio / initial_freq})\")\n",
    "    while current_duration <= end_audio:\n",
    "\n",
    "        duration = DURATION_CUT\n",
    "        create_empty_extract = False\n",
    "\n",
    "        # if RANDOM_CUT:\n",
    "        #  duration += random.randint(0, len())\n",
    "\n",
    "        class_directory = determine_class_directory(t_min, t_max, current_duration, duration, row_species, is_train)\n",
    "        is_empty_extract = \"24\" in class_directory\n",
    "\n",
    "        if is_empty_extract and number_extract_created % RATIO_EMPTY_CLASS == 0:\n",
    "            create_empty_extract = True\n",
    "\n",
    "        if class_directory == \"\":\n",
    "            current_duration += duration\n",
    "            continue\n",
    "\n",
    "        if is_empty_extract and not create_empty_extract:\n",
    "            current_duration += duration\n",
    "            number_extract_created += 1\n",
    "            continue\n",
    "\n",
    "        # print(F\"Current duration : {current_duration} => Class_directory({class_directory}) )\")\n",
    "\n",
    "        extract_path = os.path.join(class_directory, recording_id)\n",
    "        extract_path_da = os.path.join(class_directory, recording_id)\n",
    "\n",
    "        max_duration_size = len(data) - 1 if len(data) <= (int((current_duration + duration) * initial_freq)) \\\n",
    "            else (int((current_duration + duration) * initial_freq))\n",
    "\n",
    "        save_mel_spectrogramm([data[j] for j in range(int(current_duration * initial_freq),\n",
    "                                                      max_duration_size)],\n",
    "                              sample,\n",
    "                              extract_path + \"_\" + str(it) + \".png\")\n",
    "\n",
    "        if USE_DATA_AUGMENTATION and is_train is False and to_data_aug % RATIO_DATA_AUG == 0:\n",
    "            new_data = augmentations[to_data_aug % 2](samples=data, sample_rate=sample)\n",
    "            extract_path += F\"_{str(it)}__{to_data_aug}.png\"\n",
    "            extract_path_da += F\"_{str(it)}__{to_data_aug}_.png\"\n",
    "\n",
    "            save_mel_spectrogramm([new_data[j] for j in range(int(current_duration * initial_freq),\n",
    "                                                              max_duration_size)],\n",
    "                                  sample,\n",
    "                                  extract_path)\n",
    "            save_random_brig([new_data[j] for j in range(int(current_duration * initial_freq),\n",
    "                                                         max_duration_size)],\n",
    "                             sample,\n",
    "                             extract_path_da)\n",
    "\n",
    "            to_data_aug += 1\n",
    "\n",
    "        current_duration += duration\n",
    "        it += 1\n",
    "        number_extract_created += 1\n",
    "\n",
    "    # print(F\"{end_audio - current_duration} >= Minimal duration ?? )\")\n",
    "    if end_audio - current_duration >= MINIMAL_DURATION:\n",
    "        duration = DURATION_CUT\n",
    "        row_species = row_data[\"species_id\"]\n",
    "\n",
    "        class_directory = determine_class_directory(t_min, t_max, current_duration, duration, row_species, is_train)\n",
    "        if class_directory != \"\":\n",
    "            extract_path = os.path.join(class_directory, recording_id)\n",
    "\n",
    "            max_duration_size = len(data) - 1 if len(data) <= (int(end_audio * initial_freq)) \\\n",
    "                else (int(end_audio * initial_freq))\n",
    "\n",
    "            save_mel_spectrogramm([data[i] for i in range(int(current_duration * initial_freq)\n",
    "                                                          , max_duration_size)],\n",
    "                                  sample,\n",
    "                                  extract_path + \"_r.png\")\n",
    "            number_extract_created += 1\n",
    "\n",
    "\n",
    "def create_spectro_dataset():\n",
    "    table_tp = pd.read_csv(metadata_inpath).sort_values(\"recording_id\")\n",
    "\n",
    "    df_train, df_test, _, _ = train_test_split(table_tp,\n",
    "                                               table_tp[\"species_id\"],\n",
    "                                               test_size=validation_split,\n",
    "                                               random_state=50,\n",
    "                                               stratify=table_tp[\"species_id\"])\n",
    "    counter = 0\n",
    "    for index, row in df_train.iterrows():\n",
    "        print(F\"{counter}/{len(df_train.index)}\")\n",
    "        process_data_and_save_spectrogramm(row, is_train=True)\n",
    "        counter += 1\n",
    "\n",
    "    counter = 0\n",
    "    for index, row in df_test.iterrows():\n",
    "        print(F\"{counter}/{len(df_test.index)}\")\n",
    "        process_data_and_save_spectrogramm(row, is_train=False)\n",
    "        counter += 1\n",
    "\n",
    "    print('100%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_path = os.path.join(ORIGINAL_DATASET_DIRECTORY, 'test')\n",
    "initial_freq = 48000\n",
    "\n",
    "\n",
    "def create_test_spectro_dataset():\n",
    "    one_percent = int(sum([len(files) for r, d, files in os.walk(test_path)]) / 100)\n",
    "    percent = 0\n",
    "    line_count = 0\n",
    "    for file in os.listdir(test_path):\n",
    "        file_path = (os.path.join(test_path, file))\n",
    "        data, sample = sf.read(file_path)\n",
    "        end_audio = (len(data) - 1) / sample\n",
    "\n",
    "        directory_music = os.path.join(DATASET_TEST_DIRECTORY, file.replace(\".flac\", \"\"))\n",
    "        if not os.path.isdir(directory_music):\n",
    "            os.mkdir(directory_music)\n",
    "        new_file_path = (os.path.join(directory_music, file.replace(\".flac\", \"\")))\n",
    "\n",
    "        if line_count % one_percent == 0:\n",
    "            if percent % PERCENT_PRINT == 0:\n",
    "                print(str(percent) + \"%\")\n",
    "            percent += 1\n",
    "\n",
    "        duration = DURATION_CUT\n",
    "        # if RANDOM_CUT:\n",
    "        #  duration += random.randint(0, len())\n",
    "\n",
    "        current_duration = 0\n",
    "        it = 0\n",
    "        while current_duration <= end_audio:\n",
    "            max_duration_size = len(data) - 1 if len(data) <= (int((current_duration + duration) * initial_freq)) \\\n",
    "                else (int((current_duration + duration) * initial_freq))\n",
    "\n",
    "            save_spectrogramm([data[j] for j in range(int(current_duration * initial_freq),\n",
    "                                                      max_duration_size)],\n",
    "                              sample, new_file_path + \"_\" + str(it) + \".png\")\n",
    "            current_duration += duration\n",
    "            it += 1\n",
    "\n",
    "        if end_audio - current_duration >= MINIMAL_DURATION:\n",
    "            max_duration_size = len(data) - 1 if len(data) <= (int(end_audio * initial_freq)) \\\n",
    "                else (int(end_audio * initial_freq))\n",
    "\n",
    "            save_spectrogramm([data[i] for i in range(int(current_duration * initial_freq)\n",
    "                                                      , max_duration_size)],\n",
    "                              sample, new_file_path + \"_r.png\")\n",
    "\n",
    "        line_count += 1\n",
    "\n",
    "    print(\"100%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_type = [\n",
    "    \"val_train\",\n",
    "    \"test\"\n",
    "]\n",
    "\n",
    "\n",
    "def clean_dataset(dataset):\n",
    "    if dataset == dataset_type[0]:\n",
    "        for c in destination_classes:\n",
    "            folder = f'{DATASET_TRAIN_DIRECTORY}/{c}'\n",
    "            if os.path.exists(folder):\n",
    "                for filename in os.listdir(folder):\n",
    "                    os.remove(f'{folder}/{filename}')\n",
    "\n",
    "            folder = f'{DATASET_VAL_DIRECTORY}/{c}'\n",
    "            if os.path.exists(folder):\n",
    "                for filename in os.listdir(folder):\n",
    "                    os.remove(f'{folder}/{filename}')\n",
    "    else:\n",
    "        for folder in os.listdir(DATASET_TEST_DIRECTORY):\n",
    "            shutil.rmtree(os.path.join(DATASET_TEST_DIRECTORY, folder), ignore_errors=True)\n",
    "\n",
    "\n",
    "def clean_or_create_empty_folder():\n",
    "    empty_paths = [os.path.join(DATASET_VAL_DIRECTORY, \"24\"), os.path.join(DATASET_TRAIN_DIRECTORY, \"24\")]\n",
    "\n",
    "    if USE_EMPTY_CLASS:\n",
    "        for path in empty_paths:\n",
    "            if not os.path.exists(path):\n",
    "                os.mkdir(path)\n",
    "    else:\n",
    "        for path in empty_paths:\n",
    "            if os.path.exists(path):\n",
    "                os.rmdir(path)\n",
    "\n",
    "\n",
    "def clean_and_create_dataset(dataset):\n",
    "    if dataset == dataset_type[0]:\n",
    "        if not os.path.isdir(DATASET_DIRECTORY):\n",
    "            os.mkdir(DATASET_DIRECTORY)\n",
    "        if not os.path.isdir(DATASET_TRAIN_DIRECTORY):\n",
    "            os.mkdir(DATASET_TRAIN_DIRECTORY)\n",
    "        if not os.path.isdir(DATASET_VAL_DIRECTORY):\n",
    "            os.mkdir(DATASET_VAL_DIRECTORY)\n",
    "    else:\n",
    "        if not os.path.isdir(DATASET_TEST_DIRECTORY):\n",
    "            os.mkdir(DATASET_TEST_DIRECTORY)\n",
    "\n",
    "    print(F\"Cleaning {dataset} dataset...\")\n",
    "    clean_dataset(dataset)\n",
    "\n",
    "    clean_or_create_empty_folder()\n",
    "\n",
    "    print(F\"Creating {dataset} dataset...\")\n",
    "\n",
    "    if dataset == dataset_type[0]:\n",
    "        create_spectro_dataset()\n",
    "    else:\n",
    "        create_test_spectro_dataset()\n",
    "\n",
    "\n",
    "\n",
    "# Change dataset_type pour generer test_val ou test\n",
    "# 0 == train & val\n",
    "# 1 == test\n",
    "clean_and_create_dataset(dataset_type[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_classes = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(predicts, *args):\n",
    "    sum_classes = np.zeros(length_classes, dtype=np.float32)\n",
    "    for predict in predicts:\n",
    "        print(predict)\n",
    "        for i in range(length_classes):\n",
    "            sum_classes[i] += predict[i]\n",
    "    return sum_classes / len(predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random(predicts, *args):\n",
    "    return predicts[random.randint(0, len(predicts) - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def higher_than(predicts, limit):\n",
    "    limit = limit[0]\n",
    "    higher_prediction = np.zeros(length_classes, dtype=np.float32)\n",
    "    for predict in predicts:\n",
    "        for i in range(length_classes):\n",
    "            if predict[i] >= limit:\n",
    "                higher_prediction[i] += 1\n",
    "    total = sum(higher_prediction)\n",
    "    if total == 0:\n",
    "        return higher_than(predicts, (limit - limit / 3,))\n",
    "    return higher_prediction / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highest_value(predicts, *args):\n",
    "    for predict in predicts:\n",
    "        for i in range(length_classes):\n",
    "            if predict[i] >= 0.6:\n",
    "                return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute_empty(pred):\n",
    "    return_array = np.zeros(len(pred))\n",
    "    to_distribute = pred[len(pred) - 1]\n",
    "    for p in range(length_classes):\n",
    "        return_array[p] = pred[p] + (to_distribute / length_classes)\n",
    "    return return_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_save_in_submission(model: Model, func, *args):\n",
    "    with open(os.path.join(DATASET_DIRECTORY, \"submission.csv\"), mode='w', newline='') as output_csv_file:\n",
    "        writer = csv.writer(output_csv_file)\n",
    "        writer.writerow([\"recording_id\", \"s0\", \"s1\", \"s2\", \"s3\", \"s4\", \"s5\",\n",
    "                         \"s6\", \"s7\", \"s8\", \"s9\", \"s10\", \"s11\", \"s12\", \"s13\", \"s14\",\n",
    "                         \"s15\", \"s16\", \"s17\", \"s18\", \"s19\", \"s20\", \"s21\", \"s22\", \"s23\"])\n",
    "        one_percent = int(sum([len(files) for r, d, files in os.walk(DATASET_TEST_DIRECTORY)]) / 100)\n",
    "        percent = 0\n",
    "        line_count = 0\n",
    "        for _, directories, _ in os.walk(DATASET_TEST_DIRECTORY):\n",
    "            for directory in directories:\n",
    "                directory_path = os.path.join(DATASET_TEST_DIRECTORY, directory)\n",
    "                predictions = np.zeros((0, len_classes), dtype=np.float32)\n",
    "\n",
    "                for file in os.listdir(directory_path):\n",
    "                    file_path = os.path.join(directory_path, file)\n",
    "                    spectro_image = image.imread(file_path)\n",
    "                    spectro_image = np.expand_dims(spectro_image, axis=0)\n",
    "\n",
    "                    model_prediction = model.predict(spectro_image)\n",
    "\n",
    "                    # if USE_EMPTY_CLASS and model_prediction[0][len_classes - 1] >= PRED_EMPTY_IGNORE_EXTRACT:\n",
    "                    #    model_prediction[0] = np.zeros(len_classes, dtype=np.float32)\n",
    "                    if USE_EMPTY_CLASS:\n",
    "                        model_prediction[0] = distribute_empty(model_prediction[0])\n",
    "\n",
    "                    predictions = np.concatenate(\n",
    "                        (predictions,\n",
    "                         model_prediction),\n",
    "                        axis=0)\n",
    "\n",
    "                    if line_count % one_percent == 0:\n",
    "                        if percent % PERCENT_PRINT == 0:\n",
    "                            print(str(percent) + \"%\")\n",
    "                        percent += 1\n",
    "                    line_count += 1\n",
    "\n",
    "                if func is None:\n",
    "                    writer.writerow(np.insert(predictions[0].astype(np.str), 0, directory, axis=0))\n",
    "                else:\n",
    "                    writer.writerow(np.insert(func(predictions, args).astype(np.str), 0, directory, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixup DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixupImageDataGenerator():\n",
    "    def __init__(self, generator, directory, batch_size, img_height, img_width, alpha=0.2, subset=None):\n",
    "        \"\"\"Constructor for mixup image data generator.\n",
    "\n",
    "        Arguments:\n",
    "            generator {object} -- An instance of Keras ImageDataGenerator.\n",
    "            directory {str} -- Image directory.\n",
    "            batch_size {int} -- Batch size.\n",
    "            img_height {int} -- Image height in pixels.\n",
    "            img_width {int} -- Image width in pixels.\n",
    "\n",
    "        Keyword Arguments:\n",
    "            alpha {float} -- Mixup beta distribution alpha parameter. (default: {0.2})\n",
    "            subset {str} -- 'training' or 'validation' if validation_split is specified in\n",
    "            `generator` (ImageDataGenerator).(default: {None})\n",
    "        \"\"\"\n",
    "\n",
    "        self.batch_index = 0\n",
    "        self.batch_size = batch_size\n",
    "        self.alpha = alpha\n",
    "\n",
    "        # First iterator yielding tuples of (x, y)\n",
    "        self.generator1 = generator.flow_from_directory(directory,\n",
    "                                                        target_size=(\n",
    "                                                            img_height, img_width),\n",
    "                                                        class_mode=\"categorical\",\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=True,\n",
    "                                                        subset=subset)\n",
    "\n",
    "        # Second iterator yielding tuples of (x, y)\n",
    "        self.generator2 = generator.flow_from_directory(directory,\n",
    "                                                        target_size=(\n",
    "                                                            img_height, img_width),\n",
    "                                                        class_mode=\"categorical\",\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=True,\n",
    "                                                        subset=subset)\n",
    "\n",
    "        # Number of images across all classes in image directory.\n",
    "        self.n = self.generator1.samples\n",
    "\n",
    "    def reset_index(self):\n",
    "        \"\"\"Reset the generator indexes array.\n",
    "        \"\"\"\n",
    "\n",
    "        self.generator1._set_index_array()\n",
    "        self.generator2._set_index_array()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.reset_index()\n",
    "\n",
    "    def reset(self):\n",
    "        self.batch_index = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        # round up\n",
    "        return (self.n + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "    def get_steps_per_epoch(self):\n",
    "        \"\"\"Get number of steps per epoch based on batch size and\n",
    "        number of images.\n",
    "\n",
    "        Returns:\n",
    "            int -- steps per epoch.\n",
    "        \"\"\"\n",
    "\n",
    "        return self.n // self.batch_size\n",
    "\n",
    "    def __next__(self):\n",
    "        \"\"\"Get next batch input/output pair.\n",
    "\n",
    "        Returns:\n",
    "            tuple -- batch of input/output pair, (inputs, outputs).\n",
    "        \"\"\"\n",
    "\n",
    "        if self.batch_index == 0:\n",
    "            self.reset_index()\n",
    "\n",
    "        current_index = (self.batch_index * self.batch_size) % self.n\n",
    "        if self.n > current_index + self.batch_size:\n",
    "            self.batch_index += 1\n",
    "        else:\n",
    "            self.batch_index = 0\n",
    "\n",
    "        # random sample the lambda value from beta distribution.\n",
    "        l = np.random.beta(self.alpha, self.alpha, self.batch_size)\n",
    "\n",
    "        X_l = l.reshape(self.batch_size, 1, 1, 1)\n",
    "        y_l = l.reshape(self.batch_size, 1)\n",
    "\n",
    "        # Get a pair of inputs and outputs from two iterators.\n",
    "        X1, y1 = self.generator1.next()\n",
    "        X2, y2 = self.generator2.next()\n",
    "\n",
    "        # Perform the mixup.\n",
    "        X = X1 * X_l + X2 * (1 - X_l)\n",
    "        y = y1 * y_l + y2 * (1 - y_l)\n",
    "        return X, y\n",
    "\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            yield next(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_size = compute_train_images_count()\n",
    "val_size = compute_val_images_count()\n",
    "class_w = compute_class_weight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_base_model(add_custom_layers_func) -> Model:\n",
    "    m = Sequential()\n",
    "    add_custom_layers_func(m)\n",
    "\n",
    "    m.add(Flatten())\n",
    "    m.add(tf.keras.layers.Dense(len_classes, tf.keras.activations.softmax))\n",
    "\n",
    "    m.compile(optimizer=tf.keras.optimizers.SGD(lr=ref_lr / ref_batch_size * batch_size),\n",
    "              loss=tf.keras.losses.categorical_crossentropy,\n",
    "              metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_mlp_layers(model):\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    for _ in range(5):\n",
    "        model.add(tf.keras.layers.Dense(2048, activation=tf.keras.activations.linear))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Activation(activation=tf.keras.activations.tanh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_convnet(model):\n",
    "    model.add(tf.keras.layers.Reshape((IMAGE_WIDTH, IMAGE_HEIGHT)))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation=tf.keras.activations.tanh,\n",
    "                                     kernel_regularizer=tf.keras.regularizers.l2(KERNEL_REGULARIZERS)))\n",
    "    model.add(tf.keras.layers.MaxPool2D())\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation=tf.keras.activations.tanh,\n",
    "                                     kernel_regularizer=tf.keras.regularizers.l2(KERNEL_REGULARIZERS)))\n",
    "    model.add(tf.keras.layers.MaxPool2D())\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation=tf.keras.activations.tanh,\n",
    "                                     kernel_regularizer=tf.keras.regularizers.l2(KERNEL_REGULARIZERS)))\n",
    "    model.add(tf.keras.layers.MaxPool2D())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(m: Model, x_iterator, y_iterator):\n",
    "    log = m.fit(\n",
    "        x_iterator,\n",
    "        validation_data=y_iterator,\n",
    "        steps_per_epoch=train_size // batch_size,\n",
    "        validation_steps=val_size // batch_size,\n",
    "        epochs=epch,\n",
    "        class_weight=class_w\n",
    "    )\n",
    "    return log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_dataset_iterator(base_folder: str, size: int):\n",
    "    def inner_func():\n",
    "        return tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255).flow_from_directory(base_folder,\n",
    "                                                                                                      target_size=(\n",
    "                                                                                                          IMAGE_WIDTH,\n",
    "                                                                                                          IMAGE_HEIGHT),\n",
    "                                                                                                      color_mode='rgba',\n",
    "                                                                                                      batch_size=1)\n",
    "\n",
    "    return (tf.data.Dataset.from_generator(inner_func,\n",
    "                                           output_types=(tf.float32, tf.float32),\n",
    "                                           output_shapes=(\n",
    "                                               (1, *(IMAGE_WIDTH, IMAGE_HEIGHT), 4),\n",
    "                                               (1, len_classes)\n",
    "                                           )\n",
    "                                           )\n",
    "            .take(size)\n",
    "            .unbatch()\n",
    "            .batch(batch_size)\n",
    "            .cache(f'{base_folder}/cache')\n",
    "            .repeat()\n",
    "            .as_numpy_iterator()\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNet execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = create_base_model(add_convnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_logs = [\n",
    "    {\"value\": train_model(model,\n",
    "        create_dataset_iterator(DATASET_TRAIN_DIRECTORY, train_size),\n",
    "        create_dataset_iterator(DATASET_VAL_DIRECTORY, val_size)),\n",
    "    \"title\": \"add_convnet\"}\n",
    "]\n",
    "\n",
    "plot_all_logs(all_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"[Train] => \")\n",
    "model.evaluate(create_dataset_iterator(DATASET_TRAIN_DIRECTORY, train_size),\n",
    "                steps=train_size // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"[Validation] => \")\n",
    "model.evaluate(create_dataset_iterator(DATASET_VAL_DIRECTORY, val_size),\n",
    "                steps=val_size // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save prediction on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Sauvegarde des prédictions sur le jeu de test : \")\n",
    "predict_and_save_in_submission(model, higher_than, 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficient Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks():\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2,\n",
    "                                  verbose=1, mode='auto', min_delta=0.0001,\n",
    "                                  cooldown=0, min_lr=0)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor=\"val_loss\", patience=7, verbose=1, restore_best_weights=True)\n",
    "\n",
    "    model_cp = ModelCheckpoint(WEIGHT_FILE_NAME,\n",
    "                               save_best_only=True,\n",
    "                               save_weights_only=True,\n",
    "                               monitor='val_loss',\n",
    "                               mode='min', verbose=1)\n",
    "\n",
    "    return [early_stopping, model_cp, reduce_lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_efficient_net_models():\n",
    "    inputs = layers.Input(shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 3))\n",
    "\n",
    "    m = Sequential([\n",
    "        EfficientNet(include_top=False, weights='imagenet', input_tensor=inputs),\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "        layers.GlobalAveragePooling2D(name=\"avg_pool\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(dropout, name=\"top_dropout\"),\n",
    "        layers.Dense(len_classes, activation=\"tanh\", name=\"pred\")\n",
    "    ])\n",
    "    m.compile(loss=losses.CategoricalCrossentropy(),\n",
    "              optimizer=optimizers.Adam(lr=0.0001),\n",
    "              metrics=['categorical_accuracy'])\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(m, x_iterator, y_iterator):\n",
    "    log = m.fit(x_iterator,\n",
    "                validation_data=y_iterator,\n",
    "                steps_per_epoch=x_iterator.get_steps_per_epoch(),\n",
    "                validation_steps=y_iterator.samples // batch_size,\n",
    "                epochs=epch,\n",
    "                callbacks=get_callbacks())\n",
    "    return log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution de l'Efficient Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(F\"Creating model...\")\n",
    "model = create_efficient_net_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_imgen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = MixupImageDataGenerator(generator=input_imgen,\n",
    "                                              directory=DATASET_TRAIN_DIRECTORY,\n",
    "                                              batch_size=batch_size,  # To verify maybe error\n",
    "                                              img_height=IMAGE_HEIGHT,\n",
    "                                              img_width=IMAGE_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " validation_generator = input_imgen.flow_from_directory(directory=DATASET_VAL_DIRECTORY,\n",
    "                                                           target_size=(\n",
    "                                                               IMAGE_WIDTH,\n",
    "                                                               IMAGE_HEIGHT),\n",
    "                                                           batch_size=batch_size,  # To verify maybe error\n",
    "                                                           class_mode=\"categorical\",\n",
    "                                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('training steps: ', train_generator.get_steps_per_epoch())\n",
    "print('validation steps: ', validation_generator.samples // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(F\"Training model...\")\n",
    "all_logs = [\n",
    "    {\"value\": train_model(model,\n",
    "                            train_generator,\n",
    "                            validation_generator),\n",
    "     \"title\": F\"efficient_net\"}\n",
    "]\n",
    "plot_all_logs(all_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(F\"Evaluation du model...\")\n",
    "validation_generator._set_index_array()\n",
    "model.evaluate(validation_generator,\n",
    "                steps=validation_generator.samples // batch_size)\n",
    "predict_and_save_in_submission(model, higher_than, 0.35)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
