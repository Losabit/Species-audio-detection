{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: soundfile in c:\\users\\quent\\anaconda3\\lib\\site-packages (0.10.3.post1)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from soundfile) (1.14.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\quent\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile) (2.19)\n",
      "Requirement already satisfied: librosa in c:\\users\\quent\\anaconda3\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: pooch>=1.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa) (1.3.0)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa) (0.14.1)\n",
      "Requirement already satisfied: decorator>=3.0.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa) (4.4.1)\n",
      "Requirement already satisfied: audioread>=2.0.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa) (2.1.9)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa) (1.18.1)\n",
      "Requirement already satisfied: soundfile>=0.9.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa) (0.10.3.post1)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa) (0.22.1)\n",
      "Requirement already satisfied: numba>=0.43.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa) (0.48.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa) (1.4.1)\n",
      "Requirement already satisfied: resampy>=0.2.2 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa) (0.2.2)\n",
      "Requirement already satisfied: requests in c:\\users\\quent\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa) (2.22.0)\n",
      "Requirement already satisfied: appdirs in c:\\users\\quent\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\quent\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa) (20.1)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from soundfile>=0.9.0->librosa) (1.14.0)\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from numba>=0.43.0->librosa) (0.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\quent\\anaconda3\\lib\\site-packages (from numba>=0.43.0->librosa) (45.2.0.post20200210)\n",
      "Requirement already satisfied: six>=1.3 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from resampy>=0.2.2->librosa) (1.14.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from requests->pooch>=1.0->librosa) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from requests->pooch>=1.0->librosa) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from requests->pooch>=1.0->librosa) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from requests->pooch>=1.0->librosa) (2019.11.28)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from packaging->pooch>=1.0->librosa) (2.4.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\quent\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa) (2.19)\n",
      "Requirement already satisfied: audiomentations in c:\\users\\quent\\anaconda3\\lib\\site-packages (0.15.0)\n",
      "Requirement already satisfied: scipy<2,>=1.0.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from audiomentations) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.13.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from audiomentations) (1.18.1)\n",
      "Requirement already satisfied: librosa<=0.8.0,>=0.6.1 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from audiomentations) (0.8.0)\n",
      "Requirement already satisfied: soundfile>=0.9.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa<=0.8.0,>=0.6.1->audiomentations) (0.10.3.post1)\n",
      "Requirement already satisfied: decorator>=3.0.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa<=0.8.0,>=0.6.1->audiomentations) (4.4.1)\n",
      "Requirement already satisfied: numba>=0.43.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa<=0.8.0,>=0.6.1->audiomentations) (0.48.0)\n",
      "Requirement already satisfied: audioread>=2.0.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa<=0.8.0,>=0.6.1->audiomentations) (2.1.9)\n",
      "Requirement already satisfied: pooch>=1.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa<=0.8.0,>=0.6.1->audiomentations) (1.3.0)\n",
      "Requirement already satisfied: resampy>=0.2.2 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa<=0.8.0,>=0.6.1->audiomentations) (0.2.2)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa<=0.8.0,>=0.6.1->audiomentations) (0.14.1)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa<=0.8.0,>=0.6.1->audiomentations) (0.22.1)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from soundfile>=0.9.0->librosa<=0.8.0,>=0.6.1->audiomentations) (1.14.0)\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from numba>=0.43.0->librosa<=0.8.0,>=0.6.1->audiomentations) (0.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\quent\\anaconda3\\lib\\site-packages (from numba>=0.43.0->librosa<=0.8.0,>=0.6.1->audiomentations) (45.2.0.post20200210)\n",
      "Requirement already satisfied: requests in c:\\users\\quent\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa<=0.8.0,>=0.6.1->audiomentations) (2.22.0)\n",
      "Requirement already satisfied: appdirs in c:\\users\\quent\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa<=0.8.0,>=0.6.1->audiomentations) (1.4.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\quent\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa<=0.8.0,>=0.6.1->audiomentations) (20.1)\n",
      "Requirement already satisfied: six>=1.3 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from resampy>=0.2.2->librosa<=0.8.0,>=0.6.1->audiomentations) (1.14.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\quent\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa<=0.8.0,>=0.6.1->audiomentations) (2.19)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from requests->pooch>=1.0->librosa<=0.8.0,>=0.6.1->audiomentations) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from requests->pooch>=1.0->librosa<=0.8.0,>=0.6.1->audiomentations) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from requests->pooch>=1.0->librosa<=0.8.0,>=0.6.1->audiomentations) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from requests->pooch>=1.0->librosa<=0.8.0,>=0.6.1->audiomentations) (2.8)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from packaging->pooch>=1.0->librosa<=0.8.0,>=0.6.1->audiomentations) (2.4.6)\n",
      "Requirement already satisfied: tensorflow==2.3.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\quent\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==2.3.0) (3.3.0)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (0.3.3)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (2.4.1)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (1.18.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (2.3.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (0.34.2)\n",
      "Requirement already satisfied: scipy==1.4.1 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (1.4.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (1.27.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (0.11.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (1.11.2)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in c:\\users\\quent\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==2.3.0) (1.1.2)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (2.10.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (1.14.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in c:\\users\\quent\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==2.3.0) (1.6.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from tensorflow==2.3.0) (3.13.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in c:\\users\\quent\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==2.3.0) (0.2.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.3.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\quent\\appdata\\roaming\\python\\python37\\site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.7.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\quent\\appdata\\roaming\\python\\python37\\site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\quent\\appdata\\roaming\\python\\python37\\site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.22.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (45.2.0.post20200210)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\quent\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.0.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\quent\\appdata\\roaming\\python\\python37\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\quent\\appdata\\roaming\\python\\python37\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in c:\\users\\quent\\appdata\\roaming\\python\\python37\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.6)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\quent\\appdata\\roaming\\python\\python37\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.3.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.2.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\quent\\appdata\\roaming\\python\\python37\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\quent\\appdata\\roaming\\python\\python37\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install soundfile\n",
    "!pip install librosa\n",
    "!pip install audiomentations\n",
    "!pip install tensorflow==2.3.0 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os, random\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import shutil\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from audiomentations import Compose, AddGaussianNoise, AddGaussianSNR, FrequencyMask\n",
    "from datetime import datetime\n",
    "from matplotlib import image\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.python.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PROJECT_PATH = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "ORIGINAL_DATASET_DIRECTORY = os.path.join(PROJECT_PATH, 'dataset', 'rfcx-species-audio-detection')\n",
    "DATASET_DIRECTORY = os.path.join(PROJECT_PATH, 'dataset', 'spectrogram-species-audio-detection')\n",
    "DATASET_TRAIN_DIRECTORY = os.path.join(DATASET_DIRECTORY, 'train')\n",
    "DATASET_VAL_DIRECTORY = os.path.join(DATASET_DIRECTORY, 'val')\n",
    "DATASET_TEST_DIRECTORY = os.path.join(DATASET_DIRECTORY, 'test')\n",
    "WEIGHT_FILE_NAME = \"EfficientNet_Weights/EfficientNetBN_tl_best_weights.h5\"\n",
    "IMAGE_HEIGHT = 500\n",
    "IMAGE_WIDTH = 500\n",
    "\n",
    "# Créer une 25eme classe qui ne correspond à aucun oiseau\n",
    "USE_EMPTY_CLASS = True\n",
    "len_classes = 25 if USE_EMPTY_CLASS else 24\n",
    "epch = 100\n",
    "KERNEL_REGULARIZERS = 0.0005\n",
    "ref_lr = 0.03\n",
    "ref_batch_size = 16\n",
    "dropout = 0.2\n",
    "batch_size = 2\n",
    "momentumTest = 0.95\n",
    "destination_classes = [str(i) for i in range(len_classes)]\n",
    "\n",
    "### PARAMS spectrogramm_conversion ###\n",
    "# Lié à IMAGE_WIDTH et IMAGE_HEIGHT\n",
    "PERCENT_PRINT = 10\n",
    "# duration_cut -> Découpage des extraits en morceaux de x secondes / 0 = pas de découpage\n",
    "DURATION_CUT = 2\n",
    "RANDOM_CUT = True\n",
    "# Un ratio de 5 permet de sauvegarder 1 enregistrement de la 25eme classe sur 5\n",
    "# Evite d'avoir une 25eme classe trop chargée en données (sachant que 1 enregistrement contient au minimum 2 extraits)\n",
    "RATIO_EMPTY_CLASS = 40\n",
    "PRED_EMPTY_IGNORE_EXTRACT = 0.6\n",
    "# minimum duration of record\n",
    "MINIMAL_DURATION = 0.25\n",
    "MINIMAL_ANIMAL_PRESENCE = 0.25\n",
    "FREQ_MODIFIER = 0\n",
    "validation_split = 0.3\n",
    "USE_DATA_AUGMENTATION = False\n",
    "RATIO_DATA_AUG = 2\n",
    "\n",
    "\n",
    "def compute_class_images_count(base_folder: str, class_name: str):\n",
    "    return sum((1 for _ in os.listdir(f'{base_folder}/{class_name}')))\n",
    "\n",
    "\n",
    "def compute_all_classes_images_count(base_folder: str):\n",
    "    return sum((compute_class_images_count(base_folder, c) for c in destination_classes))\n",
    "\n",
    "\n",
    "def compute_train_images_count():\n",
    "    return compute_all_classes_images_count(DATASET_TRAIN_DIRECTORY)\n",
    "\n",
    "\n",
    "def compute_val_images_count():\n",
    "    return compute_all_classes_images_count(DATASET_VAL_DIRECTORY)\n",
    "\n",
    "\n",
    "def compute_total_images_count():\n",
    "    return compute_val_images_count() + compute_train_images_count()\n",
    "\n",
    "\n",
    "def compute_class_weight():\n",
    "    class_weight = {}\n",
    "    for c in destination_classes:\n",
    "        class_weight[int(c)] = compute_class_images_count(DATASET_TRAIN_DIRECTORY, c)\n",
    "        class_weight[int(c)] += compute_class_images_count(DATASET_VAL_DIRECTORY, c)\n",
    "\n",
    "    # Recuperation de la classe comportortant le moins de data\n",
    "    key_min = min(class_weight.keys(), key=(lambda k: class_weight[k]))\n",
    "    to_divide = class_weight[key_min]\n",
    "\n",
    "    for c in destination_classes:\n",
    "        class_weight[int(c)] /= to_divide\n",
    "\n",
    "    return class_weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_spectrogramm(d, s, picture_path):\n",
    "    xx, frequency, bins, im = plt.specgram(d, Fs=s)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(picture_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "    image = Image.open(picture_path)\n",
    "    image.convert('RGB').resize((IMAGE_WIDTH, IMAGE_HEIGHT)).save(picture_path)\n",
    "\n",
    "\n",
    "def save_mel_spectrogramm(d, s, picture_path):\n",
    "    spec = np.abs(librosa.stft(np.array(d), hop_length=512))\n",
    "    spec = librosa.amplitude_to_db(spec, ref=np.max)\n",
    "    librosa.display.specshow(spec, sr=s, cmap='magma')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(picture_path, bbox_inches='tight', pad_inches=0)\n",
    "    image = Image.open(picture_path)\n",
    "    image.convert('RGB').resize((IMAGE_WIDTH, IMAGE_HEIGHT)).save(picture_path)\n",
    "\n",
    "\n",
    "def save_random_brig(d, s, picture_patch):\n",
    "    spec = np.abs(librosa.stft(np.array(d), hop_length=512))\n",
    "    spec = librosa.amplitude_to_db(spec, ref=np.max)\n",
    "    librosa.display.specshow(spec, sr=s, cmap='magma')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(picture_patch, bbox_inches='tight', pad_inches=0)\n",
    "    img = Image.open(picture_patch)\n",
    "    imgArray = np.asarray(img)\n",
    "    img2 = tf.image.random_brightness(imgArray,0.2)\n",
    "    finalImag = tf.keras.preprocessing.image.array_to_img(img2)\n",
    "    finalImag.save(picture_patch)\n",
    "\n",
    "def load_data(path):\n",
    "    labels = np.zeros(0, dtype=np.float32)\n",
    "    data = np.zeros((0, IMAGE_HEIGHT, IMAGE_WIDTH, 4), dtype=np.float32)\n",
    "    for _, directories, _ in os.walk(path):\n",
    "        for directory in directories:\n",
    "            directory_path = os.path.join(path, directory)\n",
    "            for file in os.listdir(directory_path):\n",
    "                labels = np.append(labels, int(directory))\n",
    "                spectro_image = image.imread(os.path.join(directory_path, file))\n",
    "                spectro_image = np.expand_dims(spectro_image, axis=0)\n",
    "                data = np.concatenate((data, spectro_image), axis=0)\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def split_array(data_to_split, percent):\n",
    "    if percent > 1:\n",
    "        raise Exception(\"percent parameter need to be between 0 and 1\")\n",
    "\n",
    "    percent_indice = int(len(data_to_split) * percent)\n",
    "    return np.array([data_to_split[i] for i in range(percent_indice)]), \\\n",
    "           np.array([data_to_split[i] for i in range(percent_indice, len(data_to_split))])\n",
    "\n",
    "\n",
    "def build_x_y(x, y):\n",
    "    return x, tf.keras.utils.to_categorical(y, len_classes)\n",
    "\n",
    "\n",
    "def count_csv_lines(path):\n",
    "    with open(path, mode='r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        count = 0\n",
    "        for _ in reader:\n",
    "            count += 1\n",
    "        return count\n",
    "\n",
    "\n",
    "def plot_all_logs(logs):\n",
    "    print(logs)\n",
    "    metrics = ['loss', 'val_loss', 'categorical_accuracy', 'val_categorical_accuracy']\n",
    "    for metric in metrics:\n",
    "        for log in logs:\n",
    "            y_coords = log['value'].history[metric]\n",
    "            x_coords = list(range(len(y_coords)))\n",
    "            plt.plot(x_coords, y_coords)\n",
    "            plt.title(log['title'] + \" - \" + datetime.now().strftime(\"%Hh:%Mm:%Ss\") + \" - \" + metric)\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "augmentations = [\n",
    "    Compose([\n",
    "        AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "        AddGaussianSNR()\n",
    "    ]),\n",
    "    Compose([\n",
    "        FrequencyMask()\n",
    "    ])  # ,\n",
    "    # TODO : AddBackgroundNoise\n",
    "]\n",
    "\n",
    "initial_freq = 48000\n",
    "metadata_inpath = os.path.join(ORIGINAL_DATASET_DIRECTORY, 'train_tp.csv')\n",
    "audio_inpath = os.path.join(ORIGINAL_DATASET_DIRECTORY, 'train')\n",
    "number_extract_created = 0\n",
    "\n",
    "\n",
    "def determine_class_directory(t_min, t_max, current_duration, duration, species_id, is_train):\n",
    "    class_directory = \"\"\n",
    "    dataset_directory = DATASET_TRAIN_DIRECTORY if is_train else DATASET_VAL_DIRECTORY\n",
    "\n",
    "    if (t_min <= current_duration <= t_max and t_max - current_duration >= MINIMAL_ANIMAL_PRESENCE) or \\\n",
    "            (t_min <= current_duration + duration <= t_max\n",
    "             and t_max - (current_duration + duration) >= MINIMAL_ANIMAL_PRESENCE) \\\n",
    "            or (current_duration <= t_min and current_duration + duration >= t_max):\n",
    "\n",
    "        class_directory = os.path.join(dataset_directory, str(species_id))\n",
    "\n",
    "    elif USE_EMPTY_CLASS and (current_duration + duration <= t_min or current_duration >= t_max):\n",
    "        class_directory = os.path.join(dataset_directory, str(len_classes - 1))\n",
    "\n",
    "    return class_directory\n",
    "\n",
    "\n",
    "def process_data_and_save_spectrogramm(row_data, is_train):\n",
    "    global number_extract_created\n",
    "    current_duration = 0\n",
    "    it = 0\n",
    "    to_data_aug = 0\n",
    "    t_min = row_data[\"t_min\"]\n",
    "    t_max = row_data[\"t_max\"]\n",
    "    recording_id = row_data[\"recording_id\"]\n",
    "    row_species = row_data[\"species_id\"]\n",
    "\n",
    "    data, sample = sf.read(os.path.join(audio_inpath, recording_id + \".flac\"))\n",
    "    end_audio = (len(data) - 1) / sample\n",
    "\n",
    "    # print(F\"processing {recording_id}, species : {row_species} [{t_min},{t_max}] duration({end_audio / initial_freq})\")\n",
    "    while current_duration <= end_audio:\n",
    "\n",
    "        duration = DURATION_CUT\n",
    "        create_empty_extract = False\n",
    "\n",
    "        # if RANDOM_CUT:\n",
    "        #  duration += random.randint(0, len())\n",
    "\n",
    "        class_directory = determine_class_directory(t_min, t_max, current_duration, duration, row_species, is_train)\n",
    "        is_empty_extract = \"24\" in class_directory\n",
    "\n",
    "        if is_empty_extract and number_extract_created % RATIO_EMPTY_CLASS == 0:\n",
    "            create_empty_extract = True\n",
    "\n",
    "        if class_directory == \"\":\n",
    "            current_duration += duration\n",
    "            continue\n",
    "\n",
    "        if is_empty_extract and not create_empty_extract:\n",
    "            current_duration += duration\n",
    "            number_extract_created += 1\n",
    "            continue\n",
    "\n",
    "        # print(F\"Current duration : {current_duration} => Class_directory({class_directory}) )\")\n",
    "\n",
    "        extract_path = os.path.join(class_directory, recording_id)\n",
    "        extract_path_da = os.path.join(class_directory, recording_id)\n",
    "\n",
    "        max_duration_size = len(data) - 1 if len(data) <= (int((current_duration + duration) * initial_freq)) \\\n",
    "            else (int((current_duration + duration) * initial_freq))\n",
    "\n",
    "        save_spectrogramm([data[j] for j in range(int(current_duration * initial_freq),\n",
    "                                                      max_duration_size)],\n",
    "                              sample,\n",
    "                              extract_path + \"_\" + str(it) + \".png\")\n",
    "\n",
    "        if USE_DATA_AUGMENTATION and is_train is False and to_data_aug % RATIO_DATA_AUG == 0:\n",
    "            new_data = augmentations[to_data_aug % 2](samples=data, sample_rate=sample)\n",
    "            extract_path += F\"_{str(it)}__{to_data_aug}.png\"\n",
    "            extract_path_da += F\"_{str(it)}__{to_data_aug}_.png\"\n",
    "\n",
    "            save_spectrogramm([new_data[j] for j in range(int(current_duration * initial_freq),\n",
    "                                                              max_duration_size)],\n",
    "                                  sample,\n",
    "                                  extract_path)\n",
    "            save_random_brig([new_data[j] for j in range(int(current_duration * initial_freq),\n",
    "                                                         max_duration_size)],\n",
    "                             sample,\n",
    "                             extract_path_da)\n",
    "\n",
    "            to_data_aug += 1\n",
    "\n",
    "        current_duration += duration\n",
    "        it += 1\n",
    "        number_extract_created += 1\n",
    "\n",
    "    # print(F\"{end_audio - current_duration} >= Minimal duration ?? )\")\n",
    "    if end_audio - current_duration >= MINIMAL_DURATION:\n",
    "        duration = DURATION_CUT\n",
    "        row_species = row_data[\"species_id\"]\n",
    "\n",
    "        class_directory = determine_class_directory(t_min, t_max, current_duration, duration, row_species, is_train)\n",
    "        if class_directory != \"\":\n",
    "            extract_path = os.path.join(class_directory, recording_id)\n",
    "\n",
    "            max_duration_size = len(data) - 1 if len(data) <= (int(end_audio * initial_freq)) \\\n",
    "                else (int(end_audio * initial_freq))\n",
    "\n",
    "            save_spectrogramm([data[i] for i in range(int(current_duration * initial_freq)\n",
    "                                                          , max_duration_size)],\n",
    "                                  sample,\n",
    "                                  extract_path + \"_r.png\")\n",
    "            number_extract_created += 1\n",
    "\n",
    "\n",
    "def create_spectro_dataset():\n",
    "    table_tp = pd.read_csv(metadata_inpath).sort_values(\"recording_id\")\n",
    "\n",
    "    df_train, df_test, _, _ = train_test_split(table_tp,\n",
    "                                               table_tp[\"species_id\"],\n",
    "                                               test_size=validation_split,\n",
    "                                               random_state=50,\n",
    "                                               stratify=table_tp[\"species_id\"])\n",
    "    counter = 0\n",
    "    for index, row in df_train.iterrows():\n",
    "        print(F\"{counter}/{len(df_train.index)}\")\n",
    "        process_data_and_save_spectrogramm(row, is_train=True)\n",
    "        counter += 1\n",
    "\n",
    "    counter = 0\n",
    "    for index, row in df_test.iterrows():\n",
    "        print(F\"{counter}/{len(df_test.index)}\")\n",
    "        process_data_and_save_spectrogramm(row, is_train=False)\n",
    "        counter += 1\n",
    "\n",
    "    print('100%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_path = os.path.join(ORIGINAL_DATASET_DIRECTORY, 'test')\n",
    "initial_freq = 48000\n",
    "\n",
    "\n",
    "def create_test_spectro_dataset():\n",
    "    one_percent = int(sum([len(files) for r, d, files in os.walk(test_path)]) / 100)\n",
    "    percent = 0\n",
    "    line_count = 0\n",
    "    for file in os.listdir(test_path):\n",
    "        file_path = (os.path.join(test_path, file))\n",
    "        data, sample = sf.read(file_path)\n",
    "        end_audio = (len(data) - 1) / sample\n",
    "\n",
    "        directory_music = os.path.join(DATASET_TEST_DIRECTORY, file.replace(\".flac\", \"\"))\n",
    "        if not os.path.isdir(directory_music):\n",
    "            os.mkdir(directory_music)\n",
    "        new_file_path = (os.path.join(directory_music, file.replace(\".flac\", \"\")))\n",
    "\n",
    "        if line_count % one_percent == 0:\n",
    "            if percent % PERCENT_PRINT == 0:\n",
    "                print(str(percent) + \"%\")\n",
    "            percent += 1\n",
    "\n",
    "        duration = DURATION_CUT\n",
    "        # if RANDOM_CUT:\n",
    "        #  duration += random.randint(0, len())\n",
    "\n",
    "        current_duration = 0\n",
    "        it = 0\n",
    "        while current_duration <= end_audio:\n",
    "            max_duration_size = len(data) - 1 if len(data) <= (int((current_duration + duration) * initial_freq)) \\\n",
    "                else (int((current_duration + duration) * initial_freq))\n",
    "\n",
    "            save_spectrogramm([data[j] for j in range(int(current_duration * initial_freq),\n",
    "                                                      max_duration_size)],\n",
    "                              sample, new_file_path + \"_\" + str(it) + \".png\")\n",
    "            current_duration += duration\n",
    "            it += 1\n",
    "\n",
    "        if end_audio - current_duration >= MINIMAL_DURATION:\n",
    "            max_duration_size = len(data) - 1 if len(data) <= (int(end_audio * initial_freq)) \\\n",
    "                else (int(end_audio * initial_freq))\n",
    "\n",
    "            save_spectrogramm([data[i] for i in range(int(current_duration * initial_freq)\n",
    "                                                      , max_duration_size)],\n",
    "                              sample, new_file_path + \"_r.png\")\n",
    "\n",
    "        line_count += 1\n",
    "\n",
    "    print(\"100%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and creation of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning val_train dataset...\n",
      "Creating val_train dataset...\n",
      "0/851\n",
      "1/851\n",
      "2/851\n",
      "3/851\n",
      "4/851\n",
      "5/851\n",
      "6/851\n",
      "7/851\n",
      "8/851\n",
      "9/851\n",
      "10/851\n",
      "11/851\n",
      "12/851\n",
      "13/851\n",
      "14/851\n",
      "15/851\n",
      "16/851\n",
      "17/851\n",
      "18/851\n",
      "19/851\n",
      "20/851\n",
      "21/851\n",
      "22/851\n",
      "23/851\n",
      "24/851\n",
      "25/851\n",
      "26/851\n",
      "27/851\n",
      "28/851\n",
      "29/851\n",
      "30/851\n",
      "31/851\n",
      "32/851\n",
      "33/851\n",
      "34/851\n",
      "35/851\n",
      "36/851\n",
      "37/851\n",
      "38/851\n",
      "39/851\n",
      "40/851\n",
      "41/851\n",
      "42/851\n",
      "43/851\n",
      "44/851\n",
      "45/851\n",
      "46/851\n",
      "47/851\n",
      "48/851\n",
      "49/851\n",
      "50/851\n",
      "51/851\n",
      "52/851\n",
      "53/851\n",
      "54/851\n",
      "55/851\n",
      "56/851\n",
      "57/851\n",
      "58/851\n",
      "59/851\n",
      "60/851\n",
      "61/851\n",
      "62/851\n",
      "63/851\n",
      "64/851\n",
      "65/851\n",
      "66/851\n",
      "67/851\n",
      "68/851\n",
      "69/851\n",
      "70/851\n",
      "71/851\n",
      "72/851\n",
      "73/851\n",
      "74/851\n",
      "75/851\n",
      "76/851\n",
      "77/851\n",
      "78/851\n",
      "79/851\n",
      "80/851\n",
      "81/851\n",
      "82/851\n",
      "83/851\n",
      "84/851\n",
      "85/851\n",
      "86/851\n",
      "87/851\n",
      "88/851\n",
      "89/851\n",
      "90/851\n",
      "91/851\n",
      "92/851\n",
      "93/851\n",
      "94/851\n",
      "95/851\n",
      "96/851\n",
      "97/851\n",
      "98/851\n",
      "99/851\n",
      "100/851\n",
      "101/851\n",
      "102/851\n",
      "103/851\n",
      "104/851\n",
      "105/851\n",
      "106/851\n",
      "107/851\n",
      "108/851\n",
      "109/851\n",
      "110/851\n",
      "111/851\n",
      "112/851\n",
      "113/851\n",
      "114/851\n",
      "115/851\n",
      "116/851\n",
      "117/851\n",
      "118/851\n",
      "119/851\n",
      "120/851\n",
      "121/851\n",
      "122/851\n",
      "123/851\n",
      "124/851\n",
      "125/851\n",
      "126/851\n",
      "127/851\n",
      "128/851\n",
      "129/851\n",
      "130/851\n",
      "131/851\n",
      "132/851\n",
      "133/851\n",
      "134/851\n",
      "135/851\n",
      "136/851\n",
      "137/851\n",
      "138/851\n",
      "139/851\n",
      "140/851\n",
      "141/851\n",
      "142/851\n",
      "143/851\n",
      "144/851\n",
      "145/851\n",
      "146/851\n",
      "147/851\n",
      "148/851\n",
      "149/851\n",
      "150/851\n",
      "151/851\n",
      "152/851\n",
      "153/851\n",
      "154/851\n",
      "155/851\n",
      "156/851\n",
      "157/851\n",
      "158/851\n",
      "159/851\n",
      "160/851\n",
      "161/851\n",
      "162/851\n",
      "163/851\n",
      "164/851\n",
      "165/851\n",
      "166/851\n",
      "167/851\n",
      "168/851\n",
      "169/851\n",
      "170/851\n",
      "171/851\n",
      "172/851\n",
      "173/851\n",
      "174/851\n",
      "175/851\n",
      "176/851\n",
      "177/851\n",
      "178/851\n",
      "179/851\n",
      "180/851\n",
      "181/851\n",
      "182/851\n",
      "183/851\n",
      "184/851\n",
      "185/851\n",
      "186/851\n",
      "187/851\n",
      "188/851\n",
      "189/851\n",
      "190/851\n",
      "191/851\n",
      "192/851\n",
      "193/851\n",
      "194/851\n",
      "195/851\n",
      "196/851\n",
      "197/851\n",
      "198/851\n",
      "199/851\n",
      "200/851\n",
      "201/851\n",
      "202/851\n",
      "203/851\n",
      "204/851\n",
      "205/851\n",
      "206/851\n",
      "207/851\n",
      "208/851\n",
      "209/851\n",
      "210/851\n",
      "211/851\n",
      "212/851\n",
      "213/851\n",
      "214/851\n",
      "215/851\n",
      "216/851\n",
      "217/851\n",
      "218/851\n",
      "219/851\n",
      "220/851\n",
      "221/851\n",
      "222/851\n",
      "223/851\n",
      "224/851\n",
      "225/851\n",
      "226/851\n",
      "227/851\n",
      "228/851\n",
      "229/851\n",
      "230/851\n",
      "231/851\n",
      "232/851\n",
      "233/851\n",
      "234/851\n",
      "235/851\n",
      "236/851\n",
      "237/851\n",
      "238/851\n",
      "239/851\n",
      "240/851\n",
      "241/851\n",
      "242/851\n",
      "243/851\n",
      "244/851\n",
      "245/851\n",
      "246/851\n",
      "247/851\n",
      "248/851\n",
      "249/851\n",
      "250/851\n",
      "251/851\n",
      "252/851\n",
      "253/851\n",
      "254/851\n",
      "255/851\n",
      "256/851\n",
      "257/851\n",
      "258/851\n",
      "259/851\n",
      "260/851\n",
      "261/851\n",
      "262/851\n",
      "263/851\n",
      "264/851\n",
      "265/851\n",
      "266/851\n",
      "267/851\n",
      "268/851\n",
      "269/851\n",
      "270/851\n",
      "271/851\n",
      "272/851\n",
      "273/851\n",
      "274/851\n",
      "275/851\n",
      "276/851\n",
      "277/851\n",
      "278/851\n",
      "279/851\n",
      "280/851\n",
      "281/851\n",
      "282/851\n",
      "283/851\n",
      "284/851\n",
      "285/851\n",
      "286/851\n",
      "287/851\n",
      "288/851\n",
      "289/851\n",
      "290/851\n",
      "291/851\n",
      "292/851\n",
      "293/851\n",
      "294/851\n",
      "295/851\n",
      "296/851\n",
      "297/851\n",
      "298/851\n",
      "299/851\n",
      "300/851\n",
      "301/851\n",
      "302/851\n",
      "303/851\n",
      "304/851\n",
      "305/851\n",
      "306/851\n",
      "307/851\n",
      "308/851\n",
      "309/851\n",
      "310/851\n",
      "311/851\n",
      "312/851\n",
      "313/851\n",
      "314/851\n",
      "315/851\n",
      "316/851\n",
      "317/851\n",
      "318/851\n",
      "319/851\n",
      "320/851\n",
      "321/851\n",
      "322/851\n",
      "323/851\n",
      "324/851\n",
      "325/851\n",
      "326/851\n",
      "327/851\n",
      "328/851\n",
      "329/851\n",
      "330/851\n",
      "331/851\n",
      "332/851\n",
      "333/851\n",
      "334/851\n",
      "335/851\n",
      "336/851\n",
      "337/851\n",
      "338/851\n",
      "339/851\n",
      "340/851\n",
      "341/851\n",
      "342/851\n",
      "343/851\n",
      "344/851\n",
      "345/851\n",
      "346/851\n",
      "347/851\n",
      "348/851\n",
      "349/851\n",
      "350/851\n",
      "351/851\n",
      "352/851\n",
      "353/851\n",
      "354/851\n",
      "355/851\n",
      "356/851\n",
      "357/851\n",
      "358/851\n",
      "359/851\n",
      "360/851\n",
      "361/851\n",
      "362/851\n",
      "363/851\n",
      "364/851\n",
      "365/851\n",
      "366/851\n",
      "367/851\n",
      "368/851\n",
      "369/851\n",
      "370/851\n",
      "371/851\n",
      "372/851\n",
      "373/851\n",
      "374/851\n",
      "375/851\n",
      "376/851\n",
      "377/851\n",
      "378/851\n",
      "379/851\n",
      "380/851\n",
      "381/851\n",
      "382/851\n",
      "383/851\n",
      "384/851\n",
      "385/851\n",
      "386/851\n",
      "387/851\n",
      "388/851\n",
      "389/851\n",
      "390/851\n",
      "391/851\n",
      "392/851\n",
      "393/851\n",
      "394/851\n",
      "395/851\n",
      "396/851\n",
      "397/851\n",
      "398/851\n",
      "399/851\n",
      "400/851\n",
      "401/851\n",
      "402/851\n",
      "403/851\n",
      "404/851\n",
      "405/851\n",
      "406/851\n",
      "407/851\n",
      "408/851\n",
      "409/851\n",
      "410/851\n",
      "411/851\n",
      "412/851\n",
      "413/851\n",
      "414/851\n",
      "415/851\n",
      "416/851\n",
      "417/851\n",
      "418/851\n",
      "419/851\n",
      "420/851\n",
      "421/851\n",
      "422/851\n",
      "423/851\n",
      "424/851\n",
      "425/851\n",
      "426/851\n",
      "427/851\n",
      "428/851\n",
      "429/851\n",
      "430/851\n",
      "431/851\n",
      "432/851\n",
      "433/851\n",
      "434/851\n",
      "435/851\n",
      "436/851\n",
      "437/851\n",
      "438/851\n",
      "439/851\n",
      "440/851\n",
      "441/851\n",
      "442/851\n",
      "443/851\n",
      "444/851\n",
      "445/851\n",
      "446/851\n",
      "447/851\n",
      "448/851\n",
      "449/851\n",
      "450/851\n",
      "451/851\n",
      "452/851\n",
      "453/851\n",
      "454/851\n",
      "455/851\n",
      "456/851\n",
      "457/851\n",
      "458/851\n",
      "459/851\n",
      "460/851\n",
      "461/851\n",
      "462/851\n",
      "463/851\n",
      "464/851\n",
      "465/851\n",
      "466/851\n",
      "467/851\n",
      "468/851\n",
      "469/851\n",
      "470/851\n",
      "471/851\n",
      "472/851\n",
      "473/851\n",
      "474/851\n",
      "475/851\n",
      "476/851\n",
      "477/851\n",
      "478/851\n",
      "479/851\n",
      "480/851\n",
      "481/851\n",
      "482/851\n",
      "483/851\n",
      "484/851\n",
      "485/851\n",
      "486/851\n",
      "487/851\n",
      "488/851\n",
      "489/851\n",
      "490/851\n",
      "491/851\n",
      "492/851\n",
      "493/851\n",
      "494/851\n",
      "495/851\n",
      "496/851\n",
      "497/851\n",
      "498/851\n",
      "499/851\n",
      "500/851\n",
      "501/851\n",
      "502/851\n",
      "503/851\n",
      "504/851\n",
      "505/851\n",
      "506/851\n",
      "507/851\n",
      "508/851\n",
      "509/851\n",
      "510/851\n",
      "511/851\n",
      "512/851\n",
      "513/851\n",
      "514/851\n",
      "515/851\n",
      "516/851\n",
      "517/851\n",
      "518/851\n",
      "519/851\n",
      "520/851\n",
      "521/851\n",
      "522/851\n",
      "523/851\n",
      "524/851\n",
      "525/851\n",
      "526/851\n",
      "527/851\n",
      "528/851\n",
      "529/851\n",
      "530/851\n",
      "531/851\n",
      "532/851\n",
      "533/851\n",
      "534/851\n",
      "535/851\n",
      "536/851\n",
      "537/851\n",
      "538/851\n",
      "539/851\n",
      "540/851\n",
      "541/851\n",
      "542/851\n",
      "543/851\n",
      "544/851\n",
      "545/851\n",
      "546/851\n",
      "547/851\n",
      "548/851\n",
      "549/851\n",
      "550/851\n",
      "551/851\n",
      "552/851\n",
      "553/851\n",
      "554/851\n",
      "555/851\n",
      "556/851\n",
      "557/851\n",
      "558/851\n",
      "559/851\n",
      "560/851\n",
      "561/851\n",
      "562/851\n",
      "563/851\n",
      "564/851\n",
      "565/851\n",
      "566/851\n",
      "567/851\n",
      "568/851\n",
      "569/851\n",
      "570/851\n",
      "571/851\n",
      "572/851\n",
      "573/851\n",
      "574/851\n",
      "575/851\n",
      "576/851\n",
      "577/851\n",
      "578/851\n",
      "579/851\n",
      "580/851\n",
      "581/851\n",
      "582/851\n",
      "583/851\n",
      "584/851\n",
      "585/851\n",
      "586/851\n",
      "587/851\n",
      "588/851\n",
      "589/851\n",
      "590/851\n",
      "591/851\n",
      "592/851\n",
      "593/851\n",
      "594/851\n",
      "595/851\n",
      "596/851\n",
      "597/851\n",
      "598/851\n",
      "599/851\n",
      "600/851\n",
      "601/851\n",
      "602/851\n",
      "603/851\n",
      "604/851\n",
      "605/851\n",
      "606/851\n",
      "607/851\n",
      "608/851\n",
      "609/851\n",
      "610/851\n",
      "611/851\n",
      "612/851\n",
      "613/851\n",
      "614/851\n",
      "615/851\n",
      "616/851\n",
      "617/851\n",
      "618/851\n",
      "619/851\n",
      "620/851\n",
      "621/851\n",
      "622/851\n",
      "623/851\n",
      "624/851\n",
      "625/851\n",
      "626/851\n",
      "627/851\n",
      "628/851\n",
      "629/851\n",
      "630/851\n",
      "631/851\n",
      "632/851\n",
      "633/851\n",
      "634/851\n",
      "635/851\n",
      "636/851\n",
      "637/851\n",
      "638/851\n",
      "639/851\n",
      "640/851\n",
      "641/851\n",
      "642/851\n",
      "643/851\n",
      "644/851\n",
      "645/851\n",
      "646/851\n",
      "647/851\n",
      "648/851\n",
      "649/851\n",
      "650/851\n",
      "651/851\n",
      "652/851\n",
      "653/851\n",
      "654/851\n",
      "655/851\n",
      "656/851\n",
      "657/851\n",
      "658/851\n",
      "659/851\n",
      "660/851\n",
      "661/851\n",
      "662/851\n",
      "663/851\n",
      "664/851\n",
      "665/851\n",
      "666/851\n",
      "667/851\n",
      "668/851\n",
      "669/851\n",
      "670/851\n",
      "671/851\n",
      "672/851\n",
      "673/851\n",
      "674/851\n",
      "675/851\n",
      "676/851\n",
      "677/851\n",
      "678/851\n",
      "679/851\n",
      "680/851\n",
      "681/851\n",
      "682/851\n",
      "683/851\n",
      "684/851\n",
      "685/851\n",
      "686/851\n",
      "687/851\n",
      "688/851\n",
      "689/851\n",
      "690/851\n",
      "691/851\n",
      "692/851\n",
      "693/851\n",
      "694/851\n",
      "695/851\n",
      "696/851\n",
      "697/851\n",
      "698/851\n",
      "699/851\n",
      "700/851\n",
      "701/851\n",
      "702/851\n",
      "703/851\n",
      "704/851\n",
      "705/851\n",
      "706/851\n",
      "707/851\n",
      "708/851\n",
      "709/851\n",
      "710/851\n",
      "711/851\n",
      "712/851\n",
      "713/851\n",
      "714/851\n",
      "715/851\n",
      "716/851\n",
      "717/851\n",
      "718/851\n",
      "719/851\n",
      "720/851\n",
      "721/851\n",
      "722/851\n",
      "723/851\n",
      "724/851\n",
      "725/851\n",
      "726/851\n",
      "727/851\n",
      "728/851\n",
      "729/851\n",
      "730/851\n",
      "731/851\n",
      "732/851\n",
      "733/851\n",
      "734/851\n",
      "735/851\n",
      "736/851\n",
      "737/851\n",
      "738/851\n",
      "739/851\n",
      "740/851\n",
      "741/851\n",
      "742/851\n",
      "743/851\n",
      "744/851\n",
      "745/851\n",
      "746/851\n",
      "747/851\n",
      "748/851\n",
      "749/851\n",
      "750/851\n",
      "751/851\n",
      "752/851\n",
      "753/851\n",
      "754/851\n",
      "755/851\n",
      "756/851\n",
      "757/851\n",
      "758/851\n",
      "759/851\n",
      "760/851\n",
      "761/851\n",
      "762/851\n",
      "763/851\n",
      "764/851\n",
      "765/851\n",
      "766/851\n",
      "767/851\n",
      "768/851\n",
      "769/851\n",
      "770/851\n",
      "771/851\n",
      "772/851\n",
      "773/851\n",
      "774/851\n",
      "775/851\n",
      "776/851\n",
      "777/851\n",
      "778/851\n",
      "779/851\n",
      "780/851\n",
      "781/851\n",
      "782/851\n",
      "783/851\n",
      "784/851\n",
      "785/851\n",
      "786/851\n",
      "787/851\n",
      "788/851\n",
      "789/851\n",
      "790/851\n",
      "791/851\n",
      "792/851\n",
      "793/851\n",
      "794/851\n",
      "795/851\n",
      "796/851\n",
      "797/851\n",
      "798/851\n",
      "799/851\n",
      "800/851\n",
      "801/851\n",
      "802/851\n",
      "803/851\n",
      "804/851\n",
      "805/851\n",
      "806/851\n",
      "807/851\n",
      "808/851\n",
      "809/851\n",
      "810/851\n",
      "811/851\n",
      "812/851\n",
      "813/851\n",
      "814/851\n",
      "815/851\n",
      "816/851\n",
      "817/851\n",
      "818/851\n",
      "819/851\n",
      "820/851\n",
      "821/851\n",
      "822/851\n",
      "823/851\n",
      "824/851\n",
      "825/851\n",
      "826/851\n",
      "827/851\n",
      "828/851\n",
      "829/851\n",
      "830/851\n",
      "831/851\n",
      "832/851\n",
      "833/851\n",
      "834/851\n",
      "835/851\n",
      "836/851\n",
      "837/851\n",
      "838/851\n",
      "839/851\n",
      "840/851\n",
      "841/851\n",
      "842/851\n",
      "843/851\n",
      "844/851\n",
      "845/851\n",
      "846/851\n",
      "847/851\n",
      "848/851\n",
      "849/851\n",
      "850/851\n",
      "0/365\n",
      "1/365\n",
      "2/365\n",
      "3/365\n",
      "4/365\n",
      "5/365\n",
      "6/365\n",
      "7/365\n",
      "8/365\n",
      "9/365\n",
      "10/365\n",
      "11/365\n",
      "12/365\n",
      "13/365\n",
      "14/365\n",
      "15/365\n",
      "16/365\n",
      "17/365\n",
      "18/365\n",
      "19/365\n",
      "20/365\n",
      "21/365\n",
      "22/365\n",
      "23/365\n",
      "24/365\n",
      "25/365\n",
      "26/365\n",
      "27/365\n",
      "28/365\n",
      "29/365\n",
      "30/365\n",
      "31/365\n",
      "32/365\n",
      "33/365\n",
      "34/365\n",
      "35/365\n",
      "36/365\n",
      "37/365\n",
      "38/365\n",
      "39/365\n",
      "40/365\n",
      "41/365\n",
      "42/365\n",
      "43/365\n",
      "44/365\n",
      "45/365\n",
      "46/365\n",
      "47/365\n",
      "48/365\n",
      "49/365\n",
      "50/365\n",
      "51/365\n",
      "52/365\n",
      "53/365\n",
      "54/365\n",
      "55/365\n",
      "56/365\n",
      "57/365\n",
      "58/365\n",
      "59/365\n",
      "60/365\n",
      "61/365\n",
      "62/365\n",
      "63/365\n",
      "64/365\n",
      "65/365\n",
      "66/365\n",
      "67/365\n",
      "68/365\n",
      "69/365\n",
      "70/365\n",
      "71/365\n",
      "72/365\n",
      "73/365\n",
      "74/365\n",
      "75/365\n",
      "76/365\n",
      "77/365\n",
      "78/365\n",
      "79/365\n",
      "80/365\n",
      "81/365\n",
      "82/365\n",
      "83/365\n",
      "84/365\n",
      "85/365\n",
      "86/365\n",
      "87/365\n",
      "88/365\n",
      "89/365\n",
      "90/365\n",
      "91/365\n",
      "92/365\n",
      "93/365\n",
      "94/365\n",
      "95/365\n",
      "96/365\n",
      "97/365\n",
      "98/365\n",
      "99/365\n",
      "100/365\n",
      "101/365\n",
      "102/365\n",
      "103/365\n",
      "104/365\n",
      "105/365\n",
      "106/365\n",
      "107/365\n",
      "108/365\n",
      "109/365\n",
      "110/365\n",
      "111/365\n",
      "112/365\n",
      "113/365\n",
      "114/365\n",
      "115/365\n",
      "116/365\n",
      "117/365\n",
      "118/365\n",
      "119/365\n",
      "120/365\n",
      "121/365\n",
      "122/365\n",
      "123/365\n",
      "124/365\n",
      "125/365\n",
      "126/365\n",
      "127/365\n",
      "128/365\n",
      "129/365\n",
      "130/365\n",
      "131/365\n",
      "132/365\n",
      "133/365\n",
      "134/365\n",
      "135/365\n",
      "136/365\n",
      "137/365\n",
      "138/365\n",
      "139/365\n",
      "140/365\n",
      "141/365\n",
      "142/365\n",
      "143/365\n",
      "144/365\n",
      "145/365\n",
      "146/365\n",
      "147/365\n",
      "148/365\n",
      "149/365\n",
      "150/365\n",
      "151/365\n",
      "152/365\n",
      "153/365\n",
      "154/365\n",
      "155/365\n",
      "156/365\n",
      "157/365\n",
      "158/365\n",
      "159/365\n",
      "160/365\n",
      "161/365\n",
      "162/365\n",
      "163/365\n",
      "164/365\n",
      "165/365\n",
      "166/365\n",
      "167/365\n",
      "168/365\n",
      "169/365\n",
      "170/365\n",
      "171/365\n",
      "172/365\n",
      "173/365\n",
      "174/365\n",
      "175/365\n",
      "176/365\n",
      "177/365\n",
      "178/365\n",
      "179/365\n",
      "180/365\n",
      "181/365\n",
      "182/365\n",
      "183/365\n",
      "184/365\n",
      "185/365\n",
      "186/365\n",
      "187/365\n",
      "188/365\n",
      "189/365\n",
      "190/365\n",
      "191/365\n",
      "192/365\n",
      "193/365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/365\n",
      "195/365\n",
      "196/365\n",
      "197/365\n",
      "198/365\n",
      "199/365\n",
      "200/365\n",
      "201/365\n",
      "202/365\n",
      "203/365\n",
      "204/365\n",
      "205/365\n",
      "206/365\n",
      "207/365\n",
      "208/365\n",
      "209/365\n",
      "210/365\n",
      "211/365\n",
      "212/365\n",
      "213/365\n",
      "214/365\n",
      "215/365\n",
      "216/365\n",
      "217/365\n",
      "218/365\n",
      "219/365\n",
      "220/365\n",
      "221/365\n",
      "222/365\n",
      "223/365\n",
      "224/365\n",
      "225/365\n",
      "226/365\n",
      "227/365\n",
      "228/365\n",
      "229/365\n",
      "230/365\n",
      "231/365\n",
      "232/365\n",
      "233/365\n",
      "234/365\n",
      "235/365\n",
      "236/365\n",
      "237/365\n",
      "238/365\n",
      "239/365\n",
      "240/365\n",
      "241/365\n",
      "242/365\n",
      "243/365\n",
      "244/365\n",
      "245/365\n",
      "246/365\n",
      "247/365\n",
      "248/365\n",
      "249/365\n",
      "250/365\n",
      "251/365\n",
      "252/365\n",
      "253/365\n",
      "254/365\n",
      "255/365\n",
      "256/365\n",
      "257/365\n",
      "258/365\n",
      "259/365\n",
      "260/365\n",
      "261/365\n",
      "262/365\n",
      "263/365\n",
      "264/365\n",
      "265/365\n",
      "266/365\n",
      "267/365\n",
      "268/365\n",
      "269/365\n",
      "270/365\n",
      "271/365\n",
      "272/365\n",
      "273/365\n",
      "274/365\n",
      "275/365\n",
      "276/365\n",
      "277/365\n",
      "278/365\n",
      "279/365\n",
      "280/365\n",
      "281/365\n",
      "282/365\n",
      "283/365\n",
      "284/365\n",
      "285/365\n",
      "286/365\n",
      "287/365\n",
      "288/365\n",
      "289/365\n",
      "290/365\n",
      "291/365\n",
      "292/365\n",
      "293/365\n",
      "294/365\n",
      "295/365\n",
      "296/365\n",
      "297/365\n",
      "298/365\n",
      "299/365\n",
      "300/365\n",
      "301/365\n",
      "302/365\n",
      "303/365\n",
      "304/365\n",
      "305/365\n",
      "306/365\n",
      "307/365\n",
      "308/365\n",
      "309/365\n",
      "310/365\n",
      "311/365\n",
      "312/365\n",
      "313/365\n",
      "314/365\n",
      "315/365\n",
      "316/365\n",
      "317/365\n",
      "318/365\n",
      "319/365\n",
      "320/365\n",
      "321/365\n",
      "322/365\n",
      "323/365\n",
      "324/365\n",
      "325/365\n",
      "326/365\n",
      "327/365\n",
      "328/365\n",
      "329/365\n",
      "330/365\n",
      "331/365\n",
      "332/365\n",
      "333/365\n",
      "334/365\n",
      "335/365\n",
      "336/365\n",
      "337/365\n",
      "338/365\n",
      "339/365\n",
      "340/365\n",
      "341/365\n",
      "342/365\n",
      "343/365\n",
      "344/365\n",
      "345/365\n",
      "346/365\n",
      "347/365\n",
      "348/365\n",
      "349/365\n",
      "350/365\n",
      "351/365\n",
      "352/365\n",
      "353/365\n",
      "354/365\n",
      "355/365\n",
      "356/365\n",
      "357/365\n",
      "358/365\n",
      "359/365\n",
      "360/365\n",
      "361/365\n",
      "362/365\n",
      "363/365\n",
      "364/365\n",
      "100%\n"
     ]
    }
   ],
   "source": [
    "dataset_type = [\n",
    "    \"val_train\",\n",
    "    \"test\"\n",
    "]\n",
    "\n",
    "def clean_dataset(dataset):\n",
    "    if dataset == dataset_type[0]:\n",
    "        for c in destination_classes:\n",
    "            folder = f'{DATASET_TRAIN_DIRECTORY}/{c}'\n",
    "            if os.path.exists(folder):\n",
    "                for filename in os.listdir(folder):\n",
    "                    os.remove(f'{folder}/{filename}')\n",
    "\n",
    "            folder = f'{DATASET_VAL_DIRECTORY}/{c}'\n",
    "            if os.path.exists(folder):\n",
    "                for filename in os.listdir(folder):\n",
    "                    os.remove(f'{folder}/{filename}')\n",
    "    else:\n",
    "        for folder in os.listdir(DATASET_TEST_DIRECTORY):\n",
    "            shutil.rmtree(os.path.join(DATASET_TEST_DIRECTORY, folder), ignore_errors=True)\n",
    "\n",
    "\n",
    "def clean_or_create_empty_folder():\n",
    "    empty_paths = [os.path.join(DATASET_VAL_DIRECTORY, \"24\"), os.path.join(DATASET_TRAIN_DIRECTORY, \"24\")]\n",
    "\n",
    "    if USE_EMPTY_CLASS:\n",
    "        for path in empty_paths:\n",
    "            if not os.path.exists(path):\n",
    "                os.mkdir(path)\n",
    "    else:\n",
    "        for path in empty_paths:\n",
    "            if os.path.exists(path):\n",
    "                os.rmdir(path)\n",
    "\n",
    "\n",
    "def clean_and_create_dataset(dataset):\n",
    "    if dataset == dataset_type[0]:\n",
    "        if not os.path.isdir(DATASET_DIRECTORY):\n",
    "            os.mkdir(DATASET_DIRECTORY)\n",
    "        if not os.path.isdir(DATASET_TRAIN_DIRECTORY):\n",
    "            os.mkdir(DATASET_TRAIN_DIRECTORY)\n",
    "        if not os.path.isdir(DATASET_VAL_DIRECTORY):\n",
    "            os.mkdir(DATASET_VAL_DIRECTORY)\n",
    "    else:\n",
    "        if not os.path.isdir(DATASET_TEST_DIRECTORY):\n",
    "            os.mkdir(DATASET_TEST_DIRECTORY)\n",
    "\n",
    "    print(F\"Cleaning {dataset} dataset...\")\n",
    "    clean_dataset(dataset)\n",
    "\n",
    "    clean_or_create_empty_folder()\n",
    "\n",
    "    print(F\"Creating {dataset} dataset...\")\n",
    "\n",
    "    if dataset == dataset_type[0]:\n",
    "        create_spectro_dataset()\n",
    "    else:\n",
    "        create_test_spectro_dataset()\n",
    "\n",
    "\n",
    "\n",
    "# Change dataset_type pour generer test_val ou test\n",
    "# 0 == train & val\n",
    "# 1 == test\n",
    "clean_and_create_dataset(dataset_type[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(predicts, *args):\n",
    "    sum_classes = np.zeros(length_classes, dtype=np.float32)\n",
    "    for predict in predicts:\n",
    "        print(predict)\n",
    "        for i in range(length_classes):\n",
    "            sum_classes[i] += predict[i]\n",
    "    return sum_classes / len(predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random(predicts, *args):\n",
    "    return predicts[random.randint(0, len(predicts) - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def higher_than(predicts, limit):\n",
    "    limit = limit[0]\n",
    "    higher_prediction = np.zeros(length_classes, dtype=np.float32)\n",
    "    for predict in predicts:\n",
    "        for i in range(length_classes):\n",
    "            if predict[i] >= limit:\n",
    "                higher_prediction[i] += 1\n",
    "    total = sum(higher_prediction)\n",
    "    if total == 0:\n",
    "        return higher_than(predicts, (limit - limit / 3,))\n",
    "    return higher_prediction / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highest_value(predicts, *args):\n",
    "    for predict in predicts:\n",
    "        for i in range(length_classes):\n",
    "            if predict[i] >= 0.6:\n",
    "                return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute_empty(pred):\n",
    "    return_array = np.zeros(len(pred))\n",
    "    to_distribute = pred[len(pred) - 1]\n",
    "    for p in range(length_classes):\n",
    "        return_array[p] = pred[p] + (to_distribute / length_classes)\n",
    "    return return_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_save_in_submission(model: Model, func, *args):\n",
    "    with open(os.path.join(DATASET_DIRECTORY, \"submission.csv\"), mode='w', newline='') as output_csv_file:\n",
    "        writer = csv.writer(output_csv_file)\n",
    "        writer.writerow([\"recording_id\", \"s0\", \"s1\", \"s2\", \"s3\", \"s4\", \"s5\",\n",
    "                         \"s6\", \"s7\", \"s8\", \"s9\", \"s10\", \"s11\", \"s12\", \"s13\", \"s14\",\n",
    "                         \"s15\", \"s16\", \"s17\", \"s18\", \"s19\", \"s20\", \"s21\", \"s22\", \"s23\"])\n",
    "        one_percent = int(sum([len(files) for r, d, files in os.walk(DATASET_TEST_DIRECTORY)]) / 100)\n",
    "        percent = 0\n",
    "        line_count = 0\n",
    "        for _, directories, _ in os.walk(DATASET_TEST_DIRECTORY):\n",
    "            for directory in directories:\n",
    "                directory_path = os.path.join(DATASET_TEST_DIRECTORY, directory)\n",
    "                predictions = np.zeros((0, len_classes), dtype=np.float32)\n",
    "\n",
    "                for file in os.listdir(directory_path):\n",
    "                    file_path = os.path.join(directory_path, file)\n",
    "                    spectro_image = image.imread(file_path)\n",
    "                    spectro_image = np.expand_dims(spectro_image, axis=0)\n",
    "\n",
    "                    model_prediction = model.predict(spectro_image)\n",
    "\n",
    "                    # if USE_EMPTY_CLASS and model_prediction[0][len_classes - 1] >= PRED_EMPTY_IGNORE_EXTRACT:\n",
    "                    #    model_prediction[0] = np.zeros(len_classes, dtype=np.float32)\n",
    "                    if USE_EMPTY_CLASS:\n",
    "                        model_prediction[0] = distribute_empty(model_prediction[0])\n",
    "\n",
    "                    predictions = np.concatenate(\n",
    "                        (predictions,\n",
    "                         model_prediction),\n",
    "                        axis=0)\n",
    "\n",
    "                    if line_count % one_percent == 0:\n",
    "                        if percent % PERCENT_PRINT == 0:\n",
    "                            print(str(percent) + \"%\")\n",
    "                        percent += 1\n",
    "                    line_count += 1\n",
    "\n",
    "                if func is None:\n",
    "                    writer.writerow(np.insert(predictions[0].astype(np.str), 0, directory, axis=0))\n",
    "                else:\n",
    "                    writer.writerow(np.insert(func(predictions, args).astype(np.str), 0, directory, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixup DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixupImageDataGenerator():\n",
    "    def __init__(self, generator, directory, batch_size, img_height, img_width, alpha=0.2, subset=None):\n",
    "        \"\"\"Constructor for mixup image data generator.\n",
    "\n",
    "        Arguments:\n",
    "            generator {object} -- An instance of Keras ImageDataGenerator.\n",
    "            directory {str} -- Image directory.\n",
    "            batch_size {int} -- Batch size.\n",
    "            img_height {int} -- Image height in pixels.\n",
    "            img_width {int} -- Image width in pixels.\n",
    "\n",
    "        Keyword Arguments:\n",
    "            alpha {float} -- Mixup beta distribution alpha parameter. (default: {0.2})\n",
    "            subset {str} -- 'training' or 'validation' if validation_split is specified in\n",
    "            `generator` (ImageDataGenerator).(default: {None})\n",
    "        \"\"\"\n",
    "\n",
    "        self.batch_index = 0\n",
    "        self.batch_size = batch_size\n",
    "        self.alpha = alpha\n",
    "\n",
    "        # First iterator yielding tuples of (x, y)\n",
    "        self.generator1 = generator.flow_from_directory(directory,\n",
    "                                                        target_size=(\n",
    "                                                            img_height, img_width),\n",
    "                                                        class_mode=\"categorical\",\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=True,\n",
    "                                                        subset=subset)\n",
    "\n",
    "        # Second iterator yielding tuples of (x, y)\n",
    "        self.generator2 = generator.flow_from_directory(directory,\n",
    "                                                        target_size=(\n",
    "                                                            img_height, img_width),\n",
    "                                                        class_mode=\"categorical\",\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=True,\n",
    "                                                        subset=subset)\n",
    "\n",
    "        # Number of images across all classes in image directory.\n",
    "        self.n = self.generator1.samples\n",
    "\n",
    "    def reset_index(self):\n",
    "        \"\"\"Reset the generator indexes array.\n",
    "        \"\"\"\n",
    "\n",
    "        self.generator1._set_index_array()\n",
    "        self.generator2._set_index_array()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.reset_index()\n",
    "\n",
    "    def reset(self):\n",
    "        self.batch_index = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        # round up\n",
    "        return (self.n + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "    def get_steps_per_epoch(self):\n",
    "        \"\"\"Get number of steps per epoch based on batch size and\n",
    "        number of images.\n",
    "\n",
    "        Returns:\n",
    "            int -- steps per epoch.\n",
    "        \"\"\"\n",
    "\n",
    "        return self.n // self.batch_size\n",
    "\n",
    "    def __next__(self):\n",
    "        \"\"\"Get next batch input/output pair.\n",
    "\n",
    "        Returns:\n",
    "            tuple -- batch of input/output pair, (inputs, outputs).\n",
    "        \"\"\"\n",
    "\n",
    "        if self.batch_index == 0:\n",
    "            self.reset_index()\n",
    "\n",
    "        current_index = (self.batch_index * self.batch_size) % self.n\n",
    "        if self.n > current_index + self.batch_size:\n",
    "            self.batch_index += 1\n",
    "        else:\n",
    "            self.batch_index = 0\n",
    "\n",
    "        # random sample the lambda value from beta distribution.\n",
    "        l = np.random.beta(self.alpha, self.alpha, self.batch_size)\n",
    "\n",
    "        X_l = l.reshape(self.batch_size, 1, 1, 1)\n",
    "        y_l = l.reshape(self.batch_size, 1)\n",
    "\n",
    "        # Get a pair of inputs and outputs from two iterators.\n",
    "        X1, y1 = self.generator1.next()\n",
    "        X2, y2 = self.generator2.next()\n",
    "\n",
    "        # Perform the mixup.\n",
    "        X = X1 * X_l + X2 * (1 - X_l)\n",
    "        y = y1 * y_l + y2 * (1 - y_l)\n",
    "        return X, y\n",
    "\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            yield next(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2270\n",
      "990\n"
     ]
    }
   ],
   "source": [
    "train_size = compute_train_images_count()\n",
    "val_size = compute_val_images_count()\n",
    "class_w = compute_class_weight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_base_model(add_custom_layers_func) -> Model:\n",
    "    m = Sequential()\n",
    "    add_custom_layers_func(m)\n",
    "\n",
    "    m.add(Flatten())\n",
    "    m.add(tf.keras.layers.Dense(len_classes, tf.keras.activations.softmax))\n",
    "\n",
    "    m.compile(optimizer=tf.keras.optimizers.SGD(lr=ref_lr / ref_batch_size * batch_size),\n",
    "              loss=tf.keras.losses.categorical_crossentropy,\n",
    "              metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_mlp_layers(model):\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    for _ in range(5):\n",
    "        model.add(tf.keras.layers.Dense(2048, activation=tf.keras.activations.linear))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Activation(activation=tf.keras.activations.tanh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_convnet(model):\n",
    "    model.add(tf.keras.layers.Reshape((IMAGE_WIDTH, IMAGE_HEIGHT, 4)))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation=tf.keras.activations.tanh,\n",
    "                                     kernel_regularizer=tf.keras.regularizers.l2(KERNEL_REGULARIZERS)))\n",
    "    model.add(tf.keras.layers.MaxPool2D())\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation=tf.keras.activations.tanh,\n",
    "                                     kernel_regularizer=tf.keras.regularizers.l2(KERNEL_REGULARIZERS)))\n",
    "    model.add(tf.keras.layers.MaxPool2D())\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation=tf.keras.activations.tanh,\n",
    "                                     kernel_regularizer=tf.keras.regularizers.l2(KERNEL_REGULARIZERS)))\n",
    "    model.add(tf.keras.layers.MaxPool2D())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(m: Model, x_iterator, y_iterator):\n",
    "    log = m.fit(\n",
    "        x_iterator,\n",
    "        validation_data=y_iterator,\n",
    "        steps_per_epoch=train_size // batch_size,\n",
    "        validation_steps=val_size // batch_size,\n",
    "        epochs=epch,\n",
    "        class_weight=class_w\n",
    "    )\n",
    "    return log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_dataset_iterator(base_folder: str, size: int):\n",
    "    def inner_func():\n",
    "        return tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255).flow_from_directory(base_folder,\n",
    "                                                                                                      target_size=(\n",
    "                                                                                                          IMAGE_WIDTH,\n",
    "                                                                                                          IMAGE_HEIGHT),\n",
    "                                                                                                      color_mode='rgba',\n",
    "                                                                                                      batch_size=1)\n",
    "\n",
    "    return (tf.data.Dataset.from_generator(inner_func,\n",
    "                                           output_types=(tf.float32, tf.float32),\n",
    "                                           output_shapes=(\n",
    "                                               (1, *(IMAGE_WIDTH, IMAGE_HEIGHT), 4),\n",
    "                                               (1, len_classes)\n",
    "                                           )\n",
    "                                           )\n",
    "            .take(size)\n",
    "            .unbatch()\n",
    "            .batch(batch_size)\n",
    "            .cache(f'{base_folder}/cache')\n",
    "            .repeat()\n",
    "            .as_numpy_iterator()\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNet execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = create_base_model(add_convnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2270 images belonging to 25 classes.\n",
      "Epoch 1/100\n",
      "1135/1135 [==============================] - ETA: 0s - loss: 3426.1724 - categorical_accuracy: 0.1137Found 990 images belonging to 25 classes.\n",
      "Found 2270 images belonging to 25 classes.\n",
      "1135/1135 [==============================] - 101s 89ms/step - loss: 3426.1724 - categorical_accuracy: 0.1137 - val_loss: 974.7761 - val_categorical_accuracy: 0.0303\n",
      "Epoch 2/100\n",
      "1135/1135 [==============================] - 87s 77ms/step - loss: 3450.8516 - categorical_accuracy: 0.1031 - val_loss: 2675.6775 - val_categorical_accuracy: 0.2586\n",
      "Epoch 3/100\n",
      "1135/1135 [==============================] - 51s 45ms/step - loss: 3379.4539 - categorical_accuracy: 0.1053 - val_loss: 2491.5337 - val_categorical_accuracy: 0.2586\n",
      "Epoch 4/100\n",
      "1135/1135 [==============================] - 51s 45ms/step - loss: 3474.8933 - categorical_accuracy: 0.1097 - val_loss: 2426.6074 - val_categorical_accuracy: 0.2586\n",
      "Epoch 5/100\n",
      "1135/1135 [==============================] - 53s 47ms/step - loss: 3399.4336 - categorical_accuracy: 0.1137 - val_loss: 1533.4685 - val_categorical_accuracy: 0.2586\n",
      "Epoch 6/100\n",
      "1135/1135 [==============================] - 49s 43ms/step - loss: 3483.3306 - categorical_accuracy: 0.1075 - val_loss: 2420.3203 - val_categorical_accuracy: 0.2586\n",
      "Epoch 7/100\n",
      "1135/1135 [==============================] - 53s 47ms/step - loss: 3540.1858 - categorical_accuracy: 0.1022 - val_loss: 2819.3176 - val_categorical_accuracy: 0.2586\n",
      "Epoch 8/100\n",
      "1135/1135 [==============================] - 50s 44ms/step - loss: 3406.0596 - categorical_accuracy: 0.1075 - val_loss: 1472.0674 - val_categorical_accuracy: 0.2586\n",
      "Epoch 9/100\n",
      "1135/1135 [==============================] - 51s 45ms/step - loss: 3455.0266 - categorical_accuracy: 0.1053 - val_loss: 2552.1189 - val_categorical_accuracy: 0.2586\n",
      "Epoch 10/100\n",
      "1135/1135 [==============================] - 51s 45ms/step - loss: 3375.6475 - categorical_accuracy: 0.1145 - val_loss: 2261.2434 - val_categorical_accuracy: 0.2586\n",
      "Epoch 11/100\n",
      "  15/1135 [..............................] - ETA: 30s - loss: 2511.2537 - categorical_accuracy: 0.1333"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-64adb262d916>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     {\"value\": train_model(model,\n\u001b[0;32m      3\u001b[0m         \u001b[0mcreate_dataset_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATASET_TRAIN_DIRECTORY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         create_dataset_iterator(DATASET_VAL_DIRECTORY, val_size)),\n\u001b[0m\u001b[0;32m      5\u001b[0m     \"title\": \"add_convnet\"}\n\u001b[0;32m      6\u001b[0m ]\n",
      "\u001b[1;32m<ipython-input-38-a407c263591c>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(m, x_iterator, y_iterator)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_size\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_w\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     )\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1103\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    438\u001b[0m     \"\"\"\n\u001b[0;32m    439\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized hook: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    340\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_supports_tf_logs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m         \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    962\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1014\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1016\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1017\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1018\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 537\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    531\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m     \"\"\"\n\u001b[0;32m   1062\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1063\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1064\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1027\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_logs = [\n",
    "    {\"value\": train_model(model,\n",
    "        create_dataset_iterator(DATASET_TRAIN_DIRECTORY, train_size),\n",
    "        create_dataset_iterator(DATASET_VAL_DIRECTORY, val_size)),\n",
    "    \"title\": \"add_convnet\"}\n",
    "]\n",
    "\n",
    "plot_all_logs(all_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"[Train] => \")\n",
    "model.evaluate(create_dataset_iterator(DATASET_TRAIN_DIRECTORY, train_size),\n",
    "                steps=train_size // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"[Validation] => \")\n",
    "model.evaluate(create_dataset_iterator(DATASET_VAL_DIRECTORY, val_size),\n",
    "                steps=val_size // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save prediction on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Sauvegarde des prédictions sur le jeu de test : \")\n",
    "predict_and_save_in_submission(model, higher_than, 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficient Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks():\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2,\n",
    "                                  verbose=1, mode='auto', min_delta=0.0001,\n",
    "                                  cooldown=0, min_lr=0)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor=\"val_loss\", patience=7, verbose=1, restore_best_weights=True)\n",
    "\n",
    "    model_cp = ModelCheckpoint(WEIGHT_FILE_NAME,\n",
    "                               save_best_only=True,\n",
    "                               save_weights_only=True,\n",
    "                               monitor='val_loss',\n",
    "                               mode='min', verbose=1)\n",
    "\n",
    "    return [early_stopping, model_cp, reduce_lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_efficient_net_models():\n",
    "    inputs = layers.Input(shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 3))\n",
    "\n",
    "    m = Sequential([\n",
    "        EfficientNet(include_top=False, weights='imagenet', input_tensor=inputs),\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "        layers.GlobalAveragePooling2D(name=\"avg_pool\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(dropout, name=\"top_dropout\"),\n",
    "        layers.Dense(len_classes, activation=\"tanh\", name=\"pred\")\n",
    "    ])\n",
    "    m.compile(loss=losses.CategoricalCrossentropy(),\n",
    "              optimizer=optimizers.Adam(lr=0.0001),\n",
    "              metrics=['categorical_accuracy'])\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(m, x_iterator, y_iterator):\n",
    "    log = m.fit(x_iterator,\n",
    "                validation_data=y_iterator,\n",
    "                steps_per_epoch=x_iterator.get_steps_per_epoch(),\n",
    "                validation_steps=y_iterator.samples // batch_size,\n",
    "                epochs=epch,\n",
    "                callbacks=get_callbacks())\n",
    "    return log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution de l'Efficient Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from efficientnet.tfkeras import EfficientNetB1 as EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(F\"Creating model...\")\n",
    "model = create_efficient_net_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_imgen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = MixupImageDataGenerator(generator=input_imgen,\n",
    "                                              directory=DATASET_TRAIN_DIRECTORY,\n",
    "                                              batch_size=batch_size,  # To verify maybe error\n",
    "                                              img_height=IMAGE_HEIGHT,\n",
    "                                              img_width=IMAGE_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " validation_generator = input_imgen.flow_from_directory(directory=DATASET_VAL_DIRECTORY,\n",
    "                                                           target_size=(\n",
    "                                                               IMAGE_WIDTH,\n",
    "                                                               IMAGE_HEIGHT),\n",
    "                                                           batch_size=batch_size,  # To verify maybe error\n",
    "                                                           class_mode=\"categorical\",\n",
    "                                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('training steps: ', train_generator.get_steps_per_epoch())\n",
    "print('validation steps: ', validation_generator.samples // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(F\"Training model...\")\n",
    "all_logs = [\n",
    "    {\"value\": train_model(model,\n",
    "                            train_generator,\n",
    "                            validation_generator),\n",
    "     \"title\": F\"efficient_net\"}\n",
    "]\n",
    "plot_all_logs(all_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(F\"Evaluation du model...\")\n",
    "validation_generator._set_index_array()\n",
    "model.evaluate(validation_generator,\n",
    "                steps=validation_generator.samples // batch_size)\n",
    "predict_and_save_in_submission(model, higher_than, 0.35)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
