{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: soundfile in c:\\users\\quent\\anaconda3\\lib\\site-packages (0.10.3.post1)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from soundfile) (1.14.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\quent\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile) (2.19)\n",
      "Requirement already satisfied: librosa in c:\\users\\quent\\anaconda3\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: decorator>=3.0.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa) (4.4.1)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa) (0.14.1)\n",
      "Requirement already satisfied: audioread>=2.0.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa) (2.1.9)\n",
      "Requirement already satisfied: pooch>=1.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa) (1.3.0)\n",
      "Requirement already satisfied: numba>=0.43.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa) (0.48.0)\n",
      "Requirement already satisfied: soundfile>=0.9.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa) (0.10.3.post1)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa) (0.22.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa) (1.18.1)\n",
      "Requirement already satisfied: resampy>=0.2.2 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa) (0.2.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa) (1.4.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\quent\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa) (20.1)\n",
      "Requirement already satisfied: appdirs in c:\\users\\quent\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: requests in c:\\users\\quent\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa) (2.22.0)\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from numba>=0.43.0->librosa) (0.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\quent\\anaconda3\\lib\\site-packages (from numba>=0.43.0->librosa) (45.2.0.post20200210)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from soundfile>=0.9.0->librosa) (1.14.0)\n",
      "Requirement already satisfied: six>=1.3 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from resampy>=0.2.2->librosa) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from packaging->pooch>=1.0->librosa) (2.4.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from requests->pooch>=1.0->librosa) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from requests->pooch>=1.0->librosa) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from requests->pooch>=1.0->librosa) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from requests->pooch>=1.0->librosa) (2.8)\n",
      "Requirement already satisfied: pycparser in c:\\users\\quent\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa) (2.19)\n",
      "Collecting audiomentations\n",
      "  Using cached audiomentations-0.15.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: scipy<2,>=1.0.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from audiomentations) (1.4.1)\n",
      "Requirement already satisfied: librosa<=0.8.0,>=0.6.1 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from audiomentations) (0.8.0)\n",
      "Requirement already satisfied: numpy>=1.13.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from audiomentations) (1.18.1)\n",
      "Requirement already satisfied: soundfile>=0.9.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa<=0.8.0,>=0.6.1->audiomentations) (0.10.3.post1)\n",
      "Requirement already satisfied: decorator>=3.0.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa<=0.8.0,>=0.6.1->audiomentations) (4.4.1)\n",
      "Requirement already satisfied: pooch>=1.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa<=0.8.0,>=0.6.1->audiomentations) (1.3.0)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa<=0.8.0,>=0.6.1->audiomentations) (0.22.1)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa<=0.8.0,>=0.6.1->audiomentations) (0.14.1)\n",
      "Requirement already satisfied: numba>=0.43.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa<=0.8.0,>=0.6.1->audiomentations) (0.48.0)\n",
      "Requirement already satisfied: resampy>=0.2.2 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa<=0.8.0,>=0.6.1->audiomentations) (0.2.2)\n",
      "Requirement already satisfied: audioread>=2.0.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from librosa<=0.8.0,>=0.6.1->audiomentations) (2.1.9)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from soundfile>=0.9.0->librosa<=0.8.0,>=0.6.1->audiomentations) (1.14.0)\n",
      "Requirement already satisfied: appdirs in c:\\users\\quent\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa<=0.8.0,>=0.6.1->audiomentations) (1.4.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\quent\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa<=0.8.0,>=0.6.1->audiomentations) (20.1)\n",
      "Requirement already satisfied: requests in c:\\users\\quent\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa<=0.8.0,>=0.6.1->audiomentations) (2.22.0)\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from numba>=0.43.0->librosa<=0.8.0,>=0.6.1->audiomentations) (0.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\quent\\anaconda3\\lib\\site-packages (from numba>=0.43.0->librosa<=0.8.0,>=0.6.1->audiomentations) (45.2.0.post20200210)\n",
      "Requirement already satisfied: six>=1.3 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from resampy>=0.2.2->librosa<=0.8.0,>=0.6.1->audiomentations) (1.14.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\quent\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa<=0.8.0,>=0.6.1->audiomentations) (2.19)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from packaging->pooch>=1.0->librosa<=0.8.0,>=0.6.1->audiomentations) (2.4.6)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from requests->pooch>=1.0->librosa<=0.8.0,>=0.6.1->audiomentations) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from requests->pooch>=1.0->librosa<=0.8.0,>=0.6.1->audiomentations) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from requests->pooch>=1.0->librosa<=0.8.0,>=0.6.1->audiomentations) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\quent\\anaconda3\\lib\\site-packages (from requests->pooch>=1.0->librosa<=0.8.0,>=0.6.1->audiomentations) (2.8)\n",
      "Installing collected packages: audiomentations\n",
      "Successfully installed audiomentations-0.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip install soundfile\n",
    "!pip install librosa\n",
    "!pip install audiomentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import shutil\n",
    "\n",
    "from audiomentations import Compose, AddGaussianNoise, AddGaussianSNR, FrequencyMask\n",
    "from datetime import datetime\n",
    "from matplotlib import image\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_PATH = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "ORIGINAL_DATASET_DIRECTORY = os.path.join(PROJECT_PATH, 'dataset', 'rfcx-species-audio-detection')\n",
    "DATASET_DIRECTORY = os.path.join(PROJECT_PATH, 'dataset', 'spectrogram-species-audio-detection')\n",
    "DATASET_TRAIN_DIRECTORY = os.path.join(DATASET_DIRECTORY, 'train')\n",
    "DATASET_VAL_DIRECTORY = os.path.join(DATASET_DIRECTORY, 'val')\n",
    "DATASET_TEST_DIRECTORY = os.path.join(DATASET_DIRECTORY, 'test')\n",
    "WEIGHT_FILE_NAME = \"EfficientNet_Weights/EfficientNetBN_tl_best_weights.h5\"\n",
    "IMAGE_HEIGHT = 500\n",
    "IMAGE_WIDTH = 500\n",
    "\n",
    "# Créer une 25eme classe qui ne correspond à aucun oiseau\n",
    "USE_EMPTY_CLASS = True\n",
    "len_classes = 25 if USE_EMPTY_CLASS else 24\n",
    "epch = 600\n",
    "KERNEL_REGULARIZERS = 0.0005\n",
    "ref_lr = 0.03\n",
    "ref_batch_size = 16\n",
    "dropout = 0.2\n",
    "batch_size = 2\n",
    "momentumTest = 0.95\n",
    "destination_classes = [str(i) for i in range(len_classes)]\n",
    "### PARAMS spectrogramm_conversion ###\n",
    "# Lié à IMAGE_WIDTH et IMAGE_HEIGHT\n",
    "PERCENT_PRINT = 10\n",
    "# duration_cut -> Découpage des extraits en morceaux de x secondes / 0 = pas de découpage\n",
    "DURATION_CUT = 2\n",
    "RANDOM_CUT = True\n",
    "# Un ratio de 5 permet de sauvegarder 1 enregistrement de la 25eme classe sur 5\n",
    "# Evite d'avoir une 25eme classe trop chargée en données (sachant que 1 enregistrement contient au minimum 2 extraits)\n",
    "RATIO_EMPTY_CLASS = 40\n",
    "PRED_EMPTY_IGNORE_EXTRACT = 0.6\n",
    "# minimum duration of record\n",
    "MINIMAL_DURATION = 0.25\n",
    "MINIMAL_ANIMAL_PRESENCE = 0.25\n",
    "FREQ_MODIFIER = 0\n",
    "validation_split = 0.3\n",
    "USE_DATA_AUGMENTATION = False\n",
    "RATIO_DATA_AUG = 2\n",
    "\n",
    "\n",
    "def compute_class_images_count(base_folder: str, class_name: str):\n",
    "    return sum((1 for _ in os.listdir(f'{base_folder}/{class_name}')))\n",
    "\n",
    "\n",
    "def compute_all_classes_images_count(base_folder: str):\n",
    "    return sum((compute_class_images_count(base_folder, c) for c in destination_classes))\n",
    "\n",
    "\n",
    "def compute_train_images_count():\n",
    "    return compute_all_classes_images_count(DATASET_TRAIN_DIRECTORY)\n",
    "\n",
    "\n",
    "def compute_val_images_count():\n",
    "    return compute_all_classes_images_count(DATASET_VAL_DIRECTORY)\n",
    "\n",
    "\n",
    "def compute_total_images_count():\n",
    "    return compute_val_images_count() + compute_train_images_count()\n",
    "\n",
    "\n",
    "def compute_class_weight():\n",
    "    class_weight = {}\n",
    "    for c in destination_classes:\n",
    "        class_weight[int(c)] = compute_class_images_count(DATASET_TRAIN_DIRECTORY, c)\n",
    "        class_weight[int(c)] += compute_class_images_count(DATASET_VAL_DIRECTORY, c)\n",
    "\n",
    "    # Recuperation de la classe comportortant le moins de data\n",
    "    key_min = min(class_weight.keys(), key=(lambda k: class_weight[k]))\n",
    "    to_divide = class_weight[key_min]\n",
    "\n",
    "    for c in destination_classes:\n",
    "        class_weight[int(c)] /= to_divide\n",
    "\n",
    "    return class_weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_spectrogramm(d, s, picture_path):\n",
    "    xx, frequency, bins, im = plt.specgram(d, Fs=s)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(picture_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "    image = Image.open(picture_path)\n",
    "    image.convert('RGB').resize((IMAGE_WIDTH, IMAGE_HEIGHT)).save(picture_path)\n",
    "\n",
    "\n",
    "def save_mel_spectrogramm(d, s, picture_path):\n",
    "    spec = np.abs(librosa.stft(np.array(d), hop_length=512))\n",
    "    spec = librosa.amplitude_to_db(spec, ref=np.max)\n",
    "    librosa.display.specshow(spec, sr=s, cmap='magma')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(picture_path, bbox_inches='tight', pad_inches=0)\n",
    "    image = Image.open(picture_path)\n",
    "    image.convert('RGB').resize((IMAGE_WIDTH, IMAGE_HEIGHT)).save(picture_path)\n",
    "\n",
    "\n",
    "def save_random_brig(d, s, picture_patch):\n",
    "    spec = np.abs(librosa.stft(np.array(d), hop_length=512))\n",
    "    spec = librosa.amplitude_to_db(spec, ref=np.max)\n",
    "    librosa.display.specshow(spec, sr=s, cmap='magma')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(picture_patch, bbox_inches='tight', pad_inches=0)\n",
    "    img = Image.open(picture_patch)\n",
    "    imgArray = np.asarray(img)\n",
    "    img2 = tf.image.random_brightness(imgArray,0.2)\n",
    "    finalImag = tf.keras.preprocessing.image.array_to_img(img2)\n",
    "    finalImag.save(picture_patch)\n",
    "\n",
    "def load_data(path):\n",
    "    labels = np.zeros(0, dtype=np.float32)\n",
    "    data = np.zeros((0, IMAGE_HEIGHT, IMAGE_WIDTH, 4), dtype=np.float32)\n",
    "    for _, directories, _ in os.walk(path):\n",
    "        for directory in directories:\n",
    "            directory_path = os.path.join(path, directory)\n",
    "            for file in os.listdir(directory_path):\n",
    "                labels = np.append(labels, int(directory))\n",
    "                spectro_image = image.imread(os.path.join(directory_path, file))\n",
    "                spectro_image = np.expand_dims(spectro_image, axis=0)\n",
    "                data = np.concatenate((data, spectro_image), axis=0)\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def split_array(data_to_split, percent):\n",
    "    if percent > 1:\n",
    "        raise Exception(\"percent parameter need to be between 0 and 1\")\n",
    "\n",
    "    percent_indice = int(len(data_to_split) * percent)\n",
    "    return np.array([data_to_split[i] for i in range(percent_indice)]), \\\n",
    "           np.array([data_to_split[i] for i in range(percent_indice, len(data_to_split))])\n",
    "\n",
    "\n",
    "def build_x_y(x, y):\n",
    "    return x, tf.keras.utils.to_categorical(y, len_classes)\n",
    "\n",
    "\n",
    "def count_csv_lines(path):\n",
    "    with open(path, mode='r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        count = 0\n",
    "        for _ in reader:\n",
    "            count += 1\n",
    "        return count\n",
    "\n",
    "\n",
    "def plot_all_logs(logs):\n",
    "    print(logs)\n",
    "    metrics = ['loss', 'val_loss', 'categorical_accuracy', 'val_categorical_accuracy']\n",
    "    for metric in metrics:\n",
    "        for log in logs:\n",
    "            y_coords = log['value'].history[metric]\n",
    "            x_coords = list(range(len(y_coords)))\n",
    "            plt.plot(x_coords, y_coords)\n",
    "            plt.title(log['title'] + \" - \" + datetime.now().strftime(\"%Hh:%Mm:%Ss\") + \" - \" + metric)\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentations = [\n",
    "    Compose([\n",
    "        AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "        AddGaussianSNR()\n",
    "    ]),\n",
    "    Compose([\n",
    "        FrequencyMask()\n",
    "    ])  # ,\n",
    "    # TODO : AddBackgroundNoise\n",
    "]\n",
    "\n",
    "initial_freq = 48000\n",
    "metadata_inpath = os.path.join(ORIGINAL_DATASET_DIRECTORY, 'train_tp.csv')\n",
    "audio_inpath = os.path.join(ORIGINAL_DATASET_DIRECTORY, 'train')\n",
    "number_extract_created = 0\n",
    "\n",
    "\n",
    "def determine_class_directory(t_min, t_max, current_duration, duration, species_id, is_train):\n",
    "    class_directory = \"\"\n",
    "    dataset_directory = DATASET_TRAIN_DIRECTORY if is_train else DATASET_VAL_DIRECTORY\n",
    "\n",
    "    if (t_min <= current_duration <= t_max and t_max - current_duration >= MINIMAL_ANIMAL_PRESENCE) or \\\n",
    "            (t_min <= current_duration + duration <= t_max\n",
    "             and t_max - (current_duration + duration) >= MINIMAL_ANIMAL_PRESENCE) \\\n",
    "            or (current_duration <= t_min and current_duration + duration >= t_max):\n",
    "\n",
    "        class_directory = os.path.join(dataset_directory, str(species_id))\n",
    "\n",
    "    elif USE_EMPTY_CLASS and (current_duration + duration <= t_min or current_duration >= t_max):\n",
    "        class_directory = os.path.join(dataset_directory, str(len_classes - 1))\n",
    "\n",
    "    return class_directory\n",
    "\n",
    "\n",
    "def process_data_and_save_spectrogramm(row_data, is_train):\n",
    "    global number_extract_created\n",
    "    current_duration = 0\n",
    "    it = 0\n",
    "    to_data_aug = 0\n",
    "    t_min = row_data[\"t_min\"]\n",
    "    t_max = row_data[\"t_max\"]\n",
    "    recording_id = row_data[\"recording_id\"]\n",
    "    row_species = row_data[\"species_id\"]\n",
    "\n",
    "    data, sample = sf.read(os.path.join(audio_inpath, recording_id + \".flac\"))\n",
    "    end_audio = (len(data) - 1) / sample\n",
    "\n",
    "    # print(F\"processing {recording_id}, species : {row_species} [{t_min},{t_max}] duration({end_audio / initial_freq})\")\n",
    "    while current_duration <= end_audio:\n",
    "\n",
    "        duration = DURATION_CUT\n",
    "        create_empty_extract = False\n",
    "\n",
    "        # if RANDOM_CUT:\n",
    "        #  duration += random.randint(0, len())\n",
    "\n",
    "        class_directory = determine_class_directory(t_min, t_max, current_duration, duration, row_species, is_train)\n",
    "        is_empty_extract = \"24\" in class_directory\n",
    "\n",
    "        if is_empty_extract and number_extract_created % RATIO_EMPTY_CLASS == 0:\n",
    "            create_empty_extract = True\n",
    "\n",
    "        if class_directory == \"\":\n",
    "            current_duration += duration\n",
    "            continue\n",
    "\n",
    "        if is_empty_extract and not create_empty_extract:\n",
    "            current_duration += duration\n",
    "            number_extract_created += 1\n",
    "            continue\n",
    "\n",
    "        # print(F\"Current duration : {current_duration} => Class_directory({class_directory}) )\")\n",
    "\n",
    "        extract_path = os.path.join(class_directory, recording_id)\n",
    "        extract_path_da = os.path.join(class_directory, recording_id)\n",
    "\n",
    "        max_duration_size = len(data) - 1 if len(data) <= (int((current_duration + duration) * initial_freq)) \\\n",
    "            else (int((current_duration + duration) * initial_freq))\n",
    "\n",
    "        save_mel_spectrogramm([data[j] for j in range(int(current_duration * initial_freq),\n",
    "                                                      max_duration_size)],\n",
    "                              sample,\n",
    "                              extract_path + \"_\" + str(it) + \".png\")\n",
    "\n",
    "        if USE_DATA_AUGMENTATION and is_train is False and to_data_aug % RATIO_DATA_AUG == 0:\n",
    "            new_data = augmentations[to_data_aug % 2](samples=data, sample_rate=sample)\n",
    "            extract_path += F\"_{str(it)}__{to_data_aug}.png\"\n",
    "            extract_path_da += F\"_{str(it)}__{to_data_aug}_.png\"\n",
    "\n",
    "            save_mel_spectrogramm([new_data[j] for j in range(int(current_duration * initial_freq),\n",
    "                                                              max_duration_size)],\n",
    "                                  sample,\n",
    "                                  extract_path)\n",
    "            save_random_brig([new_data[j] for j in range(int(current_duration * initial_freq),\n",
    "                                                         max_duration_size)],\n",
    "                             sample,\n",
    "                             extract_path_da)\n",
    "\n",
    "            to_data_aug += 1\n",
    "\n",
    "        current_duration += duration\n",
    "        it += 1\n",
    "        number_extract_created += 1\n",
    "\n",
    "    # print(F\"{end_audio - current_duration} >= Minimal duration ?? )\")\n",
    "    if end_audio - current_duration >= MINIMAL_DURATION:\n",
    "        duration = DURATION_CUT\n",
    "        row_species = row_data[\"species_id\"]\n",
    "\n",
    "        class_directory = determine_class_directory(t_min, t_max, current_duration, duration, row_species, is_train)\n",
    "        if class_directory != \"\":\n",
    "            extract_path = os.path.join(class_directory, recording_id)\n",
    "\n",
    "            max_duration_size = len(data) - 1 if len(data) <= (int(end_audio * initial_freq)) \\\n",
    "                else (int(end_audio * initial_freq))\n",
    "\n",
    "            save_mel_spectrogramm([data[i] for i in range(int(current_duration * initial_freq)\n",
    "                                                          , max_duration_size)],\n",
    "                                  sample,\n",
    "                                  extract_path + \"_r.png\")\n",
    "            number_extract_created += 1\n",
    "\n",
    "\n",
    "def create_spectro_dataset():\n",
    "    table_tp = pd.read_csv(metadata_inpath).sort_values(\"recording_id\")\n",
    "\n",
    "    df_train, df_test, _, _ = train_test_split(table_tp,\n",
    "                                               table_tp[\"species_id\"],\n",
    "                                               test_size=validation_split,\n",
    "                                               random_state=50,\n",
    "                                               stratify=table_tp[\"species_id\"])\n",
    "    counter = 0\n",
    "    for index, row in df_train.iterrows():\n",
    "        print(F\"{counter}/{len(df_train.index)}\")\n",
    "        process_data_and_save_spectrogramm(row, is_train=True)\n",
    "        counter += 1\n",
    "\n",
    "    counter = 0\n",
    "    for index, row in df_test.iterrows():\n",
    "        print(F\"{counter}/{len(df_test.index)}\")\n",
    "        process_data_and_save_spectrogramm(row, is_train=False)\n",
    "        counter += 1\n",
    "\n",
    "    print('100%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = os.path.join(ORIGINAL_DATASET_DIRECTORY, 'test')\n",
    "initial_freq = 48000\n",
    "\n",
    "\n",
    "def create_test_spectro_dataset():\n",
    "    one_percent = int(sum([len(files) for r, d, files in os.walk(test_path)]) / 100)\n",
    "    percent = 0\n",
    "    line_count = 0\n",
    "    for file in os.listdir(test_path):\n",
    "        file_path = (os.path.join(test_path, file))\n",
    "        data, sample = sf.read(file_path)\n",
    "        end_audio = (len(data) - 1) / sample\n",
    "\n",
    "        directory_music = os.path.join(DATASET_TEST_DIRECTORY, file.replace(\".flac\", \"\"))\n",
    "        if not os.path.isdir(directory_music):\n",
    "            os.mkdir(directory_music)\n",
    "        new_file_path = (os.path.join(directory_music, file.replace(\".flac\", \"\")))\n",
    "\n",
    "        if line_count % one_percent == 0:\n",
    "            if percent % PERCENT_PRINT == 0:\n",
    "                print(str(percent) + \"%\")\n",
    "            percent += 1\n",
    "\n",
    "        duration = DURATION_CUT\n",
    "        # if RANDOM_CUT:\n",
    "        #  duration += random.randint(0, len())\n",
    "\n",
    "        current_duration = 0\n",
    "        it = 0\n",
    "        while current_duration <= end_audio:\n",
    "            max_duration_size = len(data) - 1 if len(data) <= (int((current_duration + duration) * initial_freq)) \\\n",
    "                else (int((current_duration + duration) * initial_freq))\n",
    "\n",
    "            save_spectrogramm([data[j] for j in range(int(current_duration * initial_freq),\n",
    "                                                      max_duration_size)],\n",
    "                              sample, new_file_path + \"_\" + str(it) + \".png\")\n",
    "            current_duration += duration\n",
    "            it += 1\n",
    "\n",
    "        if end_audio - current_duration >= MINIMAL_DURATION:\n",
    "            max_duration_size = len(data) - 1 if len(data) <= (int(end_audio * initial_freq)) \\\n",
    "                else (int(end_audio * initial_freq))\n",
    "\n",
    "            save_spectrogramm([data[i] for i in range(int(current_duration * initial_freq)\n",
    "                                                      , max_duration_size)],\n",
    "                              sample, new_file_path + \"_r.png\")\n",
    "\n",
    "        line_count += 1\n",
    "\n",
    "    print(\"100%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning val_train dataset...\n",
      "Creating val_train dataset...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File C:\\Users\\quent\\Desktop\\ESGI\\DL\\Species audio detection\\Jupyter\\dataset\\rfcx-species-audio-detection\\train_tp.csv does not exist: 'C:\\\\Users\\\\quent\\\\Desktop\\\\ESGI\\\\DL\\\\Species audio detection\\\\Jupyter\\\\dataset\\\\rfcx-species-audio-detection\\\\train_tp.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-05f9527e7d22>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;31m# 0 == train & val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;31m# 1 == test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m \u001b[0mclean_and_create_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_type\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-28-05f9527e7d22>\u001b[0m in \u001b[0;36mclean_and_create_dataset\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdataset_type\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mcreate_spectro_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mcreate_test_spectro_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-00a5c29de2c3>\u001b[0m in \u001b[0;36mcreate_spectro_dataset\u001b[1;34m()\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcreate_spectro_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m     \u001b[0mtable_tp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetadata_inpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"recording_id\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     df_train, df_test, _, _ = train_test_split(table_tp,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File C:\\Users\\quent\\Desktop\\ESGI\\DL\\Species audio detection\\Jupyter\\dataset\\rfcx-species-audio-detection\\train_tp.csv does not exist: 'C:\\\\Users\\\\quent\\\\Desktop\\\\ESGI\\\\DL\\\\Species audio detection\\\\Jupyter\\\\dataset\\\\rfcx-species-audio-detection\\\\train_tp.csv'"
     ]
    }
   ],
   "source": [
    "dataset_type = [\n",
    "    \"val_train\",\n",
    "    \"test\"\n",
    "]\n",
    "\n",
    "\n",
    "def clean_dataset(dataset):\n",
    "    if dataset == dataset_type[0]:\n",
    "        for c in destination_classes:\n",
    "            folder = f'{DATASET_TRAIN_DIRECTORY}/{c}'\n",
    "            if os.path.exists(folder):\n",
    "                for filename in os.listdir(folder):\n",
    "                    os.remove(f'{folder}/{filename}')\n",
    "\n",
    "            folder = f'{DATASET_VAL_DIRECTORY}/{c}'\n",
    "            if os.path.exists(folder):\n",
    "                for filename in os.listdir(folder):\n",
    "                    os.remove(f'{folder}/{filename}')\n",
    "    else:\n",
    "        for folder in os.listdir(DATASET_TEST_DIRECTORY):\n",
    "            shutil.rmtree(os.path.join(DATASET_TEST_DIRECTORY, folder), ignore_errors=True)\n",
    "\n",
    "\n",
    "def clean_or_create_empty_folder():\n",
    "    empty_paths = [os.path.join(DATASET_VAL_DIRECTORY, \"24\"), os.path.join(DATASET_TRAIN_DIRECTORY, \"24\")]\n",
    "\n",
    "    if USE_EMPTY_CLASS:\n",
    "        for path in empty_paths:\n",
    "            if not os.path.exists(path):\n",
    "                os.mkdir(path)\n",
    "    else:\n",
    "        for path in empty_paths:\n",
    "            if os.path.exists(path):\n",
    "                os.rmdir(path)\n",
    "\n",
    "\n",
    "def clean_and_create_dataset(dataset):\n",
    "    if dataset == dataset_type[0]:\n",
    "        if not os.path.isdir(DATASET_DIRECTORY):\n",
    "            os.mkdir(DATASET_DIRECTORY)\n",
    "        if not os.path.isdir(DATASET_TRAIN_DIRECTORY):\n",
    "            os.mkdir(DATASET_TRAIN_DIRECTORY)\n",
    "        if not os.path.isdir(DATASET_VAL_DIRECTORY):\n",
    "            os.mkdir(DATASET_VAL_DIRECTORY)\n",
    "    else:\n",
    "        if not os.path.isdir(DATASET_TEST_DIRECTORY):\n",
    "            os.mkdir(DATASET_TEST_DIRECTORY)\n",
    "\n",
    "    print(F\"Cleaning {dataset} dataset...\")\n",
    "    clean_dataset(dataset)\n",
    "\n",
    "    clean_or_create_empty_folder()\n",
    "\n",
    "    print(F\"Creating {dataset} dataset...\")\n",
    "\n",
    "    if dataset == dataset_type[0]:\n",
    "        create_spectro_dataset()\n",
    "    else:\n",
    "        create_test_spectro_dataset()\n",
    "\n",
    "\n",
    "\n",
    "# Change dataset_type pour generer test_val ou test\n",
    "# 0 == train & val\n",
    "# 1 == test\n",
    "clean_and_create_dataset(dataset_type[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
